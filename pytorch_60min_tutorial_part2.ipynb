{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "Neural networks can be constructed using the **torch.nn** package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical training procedure for a neural network is as follows:\n",
    "* Define the neural network that has some learnable parameters (or weights)\n",
    "* Iterate over a dataset of inputs\n",
    "* Process input through the network\n",
    "* Compute the loss (how far is the output from being correct)\n",
    "* Propagate gradients back into the network’s parameters\n",
    "* Update the weights of the network, typically using a simple update rule:\n",
    "\n",
    "weight = weight + learning_rate * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required steps in defining network:**\n",
    "* define the forward function, and the backward function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear (400 -> 120)\n",
      "  (fc2): Linear (120 -> 84)\n",
      "  (fc3): Linear (84 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learnable parameters of a model are returned by **net.parameters()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.0369 -0.1117 -0.0400  0.1009 -0.1133  0.0894  0.1449 -0.0303 -0.0012  0.0786\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The input to the forward is an \"autograd.Variable\", and so is the output.\n",
    "input = Variable(torch.randn(1, 1, 32, 32))\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zero the gradient buffers of all parameters and backprops with random gradients:\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target.\n",
    "\n",
    "**nn.MSELoss**  which computes the mean-squared error between the input and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  1\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 38.1994\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = Variable(torch.arange(1, 11))  # a dummy target, for example\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear (400 -> 120)\n",
      "  (fc2): Linear (120 -> 84)\n",
      "  (fc3): Linear (84 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.nn._functions.thnn.auto.MSELoss object at 0x7f6c71af4588>\n",
      "<torch.nn._functions.linear.Linear object at 0x7f6c71af43c8>\n",
      "<torch.nn._functions.thnn.auto.Threshold object at 0x7f6c71af42e8>\n"
     ]
    }
   ],
   "source": [
    "print(loss.creator)  # MSELoss\n",
    "print(loss.creator.previous_functions[0][0])  # Linear\n",
    "print(loss.creator.previous_functions[0][0].previous_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backprop\n",
    "use loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad after backward\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      " -1.9524\n",
      "  7.5726\n",
      "  1.7037\n",
      " -1.3146\n",
      "  2.3099\n",
      "  9.6973\n",
      "[torch.FloatTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Later:**\n",
    "\n",
    "  The neural network package contains various modules and loss functions\n",
    "  that form the building blocks of deep neural networks. A full list with\n",
    "  documentation is `here <http://pytorch.org/docs/nn>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the weights\n",
    "weight = weight - learning_rate * gradient\n",
    "\n",
    "use **torch.optim** package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       "   0.0873 -0.0059 -0.0492 -0.0136  0.1793\n",
       "  -0.1611 -0.0533 -0.1136 -0.0417  0.0482\n",
       "  -0.0747  0.1269  0.1576 -0.1951 -0.1203\n",
       "  -0.1475  0.1606 -0.0976  0.1815  0.1100\n",
       "   0.1899  0.1216 -0.1929 -0.1596  0.1579\n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       "  -0.1146  0.0567  0.0032  0.0509  0.0041\n",
       "  -0.1551  0.0860 -0.1748  0.0678  0.1489\n",
       "  -0.0924 -0.0004 -0.0500 -0.1250  0.1926\n",
       "   0.1996  0.0404  0.0676 -0.1631  0.0479\n",
       "  -0.1213  0.0513 -0.0763  0.1673 -0.0726\n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       "  -0.1124  0.0551 -0.1044 -0.1034  0.1417\n",
       "   0.0866 -0.0229 -0.0657  0.1107  0.1507\n",
       "  -0.0354  0.1142  0.1559  0.1049 -0.0169\n",
       "   0.1865  0.1946 -0.1684  0.1034 -0.1876\n",
       "  -0.1860 -0.0243  0.1977 -0.0003  0.1304\n",
       " \n",
       " (3 ,0 ,.,.) = \n",
       "   0.1723  0.1554 -0.1660  0.1960 -0.1823\n",
       "  -0.1088 -0.0267 -0.0900 -0.0803  0.0254\n",
       "  -0.1217  0.0401  0.0257 -0.0709 -0.0452\n",
       "   0.1383  0.1107  0.1414 -0.0501 -0.1518\n",
       "   0.0832 -0.0843 -0.0203 -0.1782  0.0806\n",
       " \n",
       " (4 ,0 ,.,.) = \n",
       "   0.0699 -0.1080  0.1186 -0.0550  0.0039\n",
       "  -0.0413 -0.0849 -0.1690  0.1300  0.1516\n",
       "  -0.1629 -0.1506  0.1162  0.0669  0.1910\n",
       "   0.0665  0.0909 -0.1762  0.0740  0.0489\n",
       "   0.1665 -0.0649  0.1720  0.1225  0.1876\n",
       " \n",
       " (5 ,0 ,.,.) = \n",
       "  -0.0947  0.1314 -0.0162  0.1519 -0.1807\n",
       "  -0.0201 -0.0948 -0.1952 -0.1356  0.1225\n",
       "   0.0042  0.1909  0.1012 -0.0048  0.1198\n",
       "   0.0858  0.1414  0.1264 -0.0461 -0.1194\n",
       "   0.1473 -0.0860  0.1223 -0.0525  0.1236\n",
       " [torch.FloatTensor of size 6x1x5x5], Parameter containing:\n",
       " -0.0106\n",
       "  0.1550\n",
       "  0.0874\n",
       "  0.1685\n",
       " -0.0995\n",
       " -0.1014\n",
       " [torch.FloatTensor of size 6], Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -2.6292 -2.1235 -0.9248 -3.3898 -2.9190\n",
       "  -4.4922 -6.2348  1.9722 -7.7932 -4.5893\n",
       "  -4.7999 -2.8457 -2.0781 -4.1127 -5.1246\n",
       "   6.9045  8.0742  6.6853 -5.6906  4.3423\n",
       "   2.0908 -0.5176  2.7301 -3.6584 -1.7568\n",
       " \n",
       " (0 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -3.0610 -5.5163  6.2007 -6.5379  0.7630\n",
       "  -7.9840 -7.5505  7.3588 -5.2989 -3.2154\n",
       "  -3.0109 -2.7504  5.1822  2.2651  0.8475\n",
       "   8.1209  2.9554  2.4018 -4.9702  5.0926\n",
       "   2.0961  5.7680 -5.3826 -0.9043  1.2700\n",
       " \n",
       " (0 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -7.1484  6.7261  7.5770 -1.9118  6.4701\n",
       "   5.3943  0.9421  0.5384 -3.7857  3.0922\n",
       "   6.7130  1.6379 -2.8124 -1.8370  7.3483\n",
       "  -3.6000 -5.3765  4.9202  2.7419 -2.2362\n",
       "   0.7798  7.3261 -5.2057  4.6678  2.8218\n",
       " \n",
       " (0 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -7.1263  5.3719  2.6987 -0.1998  0.1361\n",
       "  -7.5618 -2.3841 -6.0327  6.8444 -6.1496\n",
       "   6.5044 -0.8038  1.6592  7.4544  1.2577\n",
       "  -4.5030 -6.9630  7.0649  0.0477  0.8942\n",
       "  -4.5484 -4.0136 -5.9040 -4.7362 -7.9176\n",
       " \n",
       " (0 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   7.2709  7.1135 -3.0953 -5.9531  3.8129\n",
       "   1.8194 -5.0503  0.1007  6.9344  4.2285\n",
       "  -7.6334  6.3645 -2.7222 -6.9036  6.7892\n",
       "   3.9149  0.8922 -0.6915 -5.5319 -3.7507\n",
       "  -7.2090  5.6623  7.9248 -1.6093 -7.4997\n",
       " \n",
       " (0 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -2.6442 -3.6329 -2.0093  2.6964 -7.5309\n",
       "  -2.9906  3.2204 -7.7534 -6.0236  5.0750\n",
       "   4.1899 -3.0539  6.2579 -0.5188  1.1171\n",
       "   5.3710 -6.9074 -6.7383 -2.9525 -4.3693\n",
       "  -5.1963 -1.7761  6.2952 -4.4105 -5.9320\n",
       "      ⋮ \n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -5.6859 -2.3973  6.5196  6.3829 -7.9272\n",
       "   5.2427  7.4846  5.5329 -4.7480 -6.4405\n",
       "  -4.2968 -2.4781 -3.3634  7.6136  1.4067\n",
       "  -0.9022  0.3204  1.7292  3.7358  3.0393\n",
       "  -5.6767 -4.1517 -2.9516  8.0822  3.3824\n",
       " \n",
       " (1 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -2.6668  6.7550  1.4346 -7.7305  3.7786\n",
       "  -3.6337  1.5792  5.8791  0.0475 -1.0458\n",
       "   4.4863  5.7709  8.0095  0.8910 -0.8552\n",
       "  -1.4656 -6.4295  5.4511  6.1588 -6.2471\n",
       "   5.5093  6.7405 -4.5957 -7.2165  7.4842\n",
       " \n",
       " (1 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.3021 -7.6122 -0.2988  5.7834  7.8829\n",
       "  -0.2236  4.4542 -2.7633  4.3797 -7.9945\n",
       "  -2.8807 -4.2577 -8.0666 -0.4863 -1.2187\n",
       "   7.6646  5.2406  7.0009  1.2748  4.2194\n",
       "   2.6099  7.6379  6.6225 -6.6038  4.1705\n",
       " \n",
       " (1 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   7.9024  7.0777 -5.4347 -2.8749 -6.7360\n",
       "  -4.9730 -1.8555 -0.4853  6.3220  6.7377\n",
       "  -6.9071 -0.3511  5.7792  6.6781  0.1973\n",
       "  -6.3174  6.5740  1.0336  3.9257 -0.1938\n",
       "  -2.6235 -7.2378 -2.7158  2.2289 -0.4895\n",
       " \n",
       " (1 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -5.8026 -1.1191 -2.8307  6.7521 -3.2419\n",
       "   0.4851 -1.4196  6.5171  3.5288  1.2283\n",
       "   0.9616 -7.9448 -8.1274  2.5358 -1.2092\n",
       "  -3.6570 -4.4660  2.0301 -1.9661  0.7169\n",
       "  -2.2806  5.8187  6.1151 -1.5915 -5.4541\n",
       " \n",
       " (1 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -6.8117 -5.2602  3.0894  0.3060  0.0284\n",
       "  -4.4056  6.7932 -2.4771 -5.8886  0.4476\n",
       "  -0.1214 -5.4399 -0.3014  6.2004  2.2998\n",
       "   3.0796 -7.3694 -6.4956 -1.1420  3.2383\n",
       "   2.2493 -6.6903 -5.9179 -5.8914 -1.6387\n",
       "      ⋮ \n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -1.2802  4.0585 -0.9999  1.7113 -5.6461\n",
       "   4.1218 -4.1397 -2.9544 -6.0097  5.8552\n",
       "  -0.2163 -6.3054  1.3200 -2.6400  3.3268\n",
       "  -3.5228 -4.2471  2.9538 -7.7758 -7.6848\n",
       "   6.1621  0.3873 -7.3087 -4.3242 -7.9874\n",
       " \n",
       " (2 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -2.0141  3.6569  5.2536 -2.5278 -4.9284\n",
       "  -7.9581  1.0997 -7.7046  4.3976  4.1537\n",
       "   7.9547  5.0272  5.8510 -2.8055  0.4934\n",
       "   4.0636 -6.9958  1.5986  3.4059  5.1610\n",
       "  -7.3493  1.4174  1.3071 -5.8671 -6.8865\n",
       " \n",
       " (2 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.8153  2.3336 -7.8832  2.2025 -8.0799\n",
       "  -4.5883  1.9676  5.6674 -5.4145 -1.6929\n",
       "   4.4307  2.2219  3.2787 -2.0690 -0.7398\n",
       "  -8.0912 -5.9937  2.6593 -6.2713 -4.8925\n",
       "  -3.5468 -1.4482  3.7199  5.3060 -1.1437\n",
       " \n",
       " (2 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   3.5939  6.5360  8.0420  5.6529 -0.5579\n",
       "  -6.5238 -4.9835  4.6207  4.1701  3.6060\n",
       "  -7.9203  0.7690 -3.6690 -2.6105  2.0717\n",
       "  -1.2982  3.0124  2.6773  3.0081  6.6392\n",
       "  -4.8955  2.3406 -7.9622  0.3828  4.5272\n",
       " \n",
       " (2 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -7.1682  3.5757 -6.2604 -2.4150  1.7792\n",
       "  -2.4871  6.2217  1.1604  5.0791  2.3656\n",
       "   1.2308 -4.9893 -2.2814 -1.4140  5.8412\n",
       "  -6.8191  6.8583 -2.6032  0.2670 -5.3899\n",
       "  -3.6197 -2.1447 -3.6218 -4.0791 -1.2808\n",
       " \n",
       " (2 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   4.2429  3.5866  7.0186 -3.6969 -6.4439\n",
       "   6.0213 -5.0388 -4.5577 -1.2142 -0.6877\n",
       "   4.1005 -4.5991 -6.4008 -3.0510 -4.8380\n",
       "   2.5655  3.4753 -1.7351 -6.3684 -5.8030\n",
       "   2.5160  4.8265  3.4267 -4.6663  0.3529\n",
       " ...   \n",
       "      ⋮ \n",
       " \n",
       " (13,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   2.8785 -4.2458 -7.6192 -2.3749 -3.8340\n",
       "   4.7388 -3.4752 -4.3516 -6.2824  6.9074\n",
       "   0.4669 -3.9466  4.5094  2.8123 -7.4070\n",
       "  -1.3095  3.7193  0.1173  4.0622 -1.5893\n",
       "  -5.8563  2.7586  0.3383 -3.8725  2.9383\n",
       " \n",
       " (13,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   5.7932  3.8819  0.5247  4.8472  2.1534\n",
       "  -5.4070  4.8850 -2.8802  5.3394  4.3100\n",
       "  -5.2923 -6.1770 -4.6181 -1.8384  7.9919\n",
       "   1.4844 -7.5164  7.9663 -8.0983  1.2633\n",
       "  -3.9901 -1.0455  1.0374  5.2380 -7.9131\n",
       " \n",
       " (13,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   7.4427  0.0105 -1.1027 -1.9108  3.8452\n",
       "  -3.6556  0.5766 -3.7767 -2.6682  7.7381\n",
       "  -3.3164 -2.6961 -3.0743 -0.3427 -4.5853\n",
       "   0.2378  6.3889 -0.1807  6.4331  4.1564\n",
       "  -0.3794  6.0879 -4.6653  6.3281  7.6734\n",
       " \n",
       " (13,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   7.8033  4.8415  5.7445  1.1274 -2.7388\n",
       "  -2.8546  7.5844  1.8107 -5.1432  8.1616\n",
       "   2.7242 -7.5129  7.5316  4.7732  7.2271\n",
       "  -3.2240 -1.6508  3.4609  0.9553  5.4632\n",
       "  -0.7791  6.1808 -1.5931 -3.3703 -3.1781\n",
       " \n",
       " (13,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   6.2577  3.9338  2.2379  6.6266  7.4534\n",
       "   3.2963  7.1080  7.3567 -7.5528 -0.8921\n",
       "  -2.1343  0.6099  4.2779  7.7655  4.9410\n",
       "   5.6485  6.7164 -8.0374  2.2563  3.0635\n",
       "   5.7576  0.7278  6.3750 -7.0097  6.9932\n",
       " \n",
       " (13,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   3.6615  0.4590  1.8086 -0.9162  5.3618\n",
       "   4.7847  3.5256 -2.2699 -0.4764 -7.6726\n",
       "  -3.1786  2.4027 -7.9821 -4.4786 -4.1068\n",
       "   2.5787 -2.1125 -8.1031  2.0258  5.8427\n",
       "   7.5314 -3.8788  8.0374 -1.9666 -0.7603\n",
       "      ⋮ \n",
       " \n",
       " (14,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -6.9528  5.4071  0.3603  0.2441  2.6296\n",
       "   4.7328  1.3698 -6.5989  5.0255 -2.9272\n",
       "   5.5141  0.8480  0.0152  7.1147  0.8299\n",
       "   3.3275  0.0448 -3.3096 -0.3826 -4.7148\n",
       "   3.1419  5.3382 -1.8289 -1.0043  1.1404\n",
       " \n",
       " (14,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -2.4387  6.4668  1.7190  5.6883  2.6065\n",
       "   2.8442 -7.0781  7.9691  3.6906  1.2582\n",
       "   3.5695  5.6469 -4.9590  1.7080 -8.1418\n",
       "  -1.7665 -6.3207  0.0507 -3.5061 -8.0014\n",
       "   6.9919 -0.4267 -1.9444 -5.3228 -7.8789\n",
       " \n",
       " (14,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -7.2166  1.1501 -4.9003 -0.8248 -3.3560\n",
       "   6.0421  3.9107  6.0085  0.1094 -7.8995\n",
       "   8.0986 -0.5694 -5.9673 -1.2901 -0.1824\n",
       "  -3.8415 -3.8338  0.4592 -4.7475 -2.0632\n",
       "   6.3618 -3.1380 -2.2172 -6.4822 -5.5548\n",
       " \n",
       " (14,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   1.6915  1.4505 -3.9564 -5.8456  1.2277\n",
       "   6.5996 -3.5324  1.6263 -2.6597  2.6100\n",
       "  -1.2660 -5.5016 -4.0853  3.2168  6.0849\n",
       "   2.3814  5.0194 -4.3679 -4.7129 -3.7194\n",
       "   1.8860  3.9821 -2.0006 -2.1260  3.8505\n",
       " \n",
       " (14,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   6.0213  6.6475  7.0561 -5.7160 -3.8071\n",
       "   1.8748 -3.3912  0.3657  4.4994  1.9209\n",
       "   6.0076 -4.6233  6.6748 -0.7843 -4.5653\n",
       "  -6.3398  4.3621 -1.4933  3.9858  7.3242\n",
       "   5.9606  6.6840  5.1421 -1.1090 -5.0022\n",
       " \n",
       " (14,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   1.4683  0.6870 -2.5656 -5.0843 -0.5007\n",
       "  -2.7764  2.4303  8.1432 -5.4240 -0.2291\n",
       "  -6.1702  0.7404  3.9310 -5.0894  4.2277\n",
       "  -1.9802 -6.5874 -1.3293  7.1838 -4.1104\n",
       "  -6.4135 -1.4819 -1.1199  0.8444 -6.8558\n",
       "      ⋮ \n",
       " \n",
       " (15,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   3.8171  5.7977  7.6108  3.9218  0.0567\n",
       "   0.7436  4.8091  5.9494 -6.2960  5.8457\n",
       "  -7.5116 -6.6685 -3.5724  5.5278  1.6459\n",
       "  -7.6903  3.8639 -5.6927 -2.2503  5.3857\n",
       "   0.0680  0.1107 -6.9482  0.5686 -3.0054\n",
       " \n",
       " (15,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -4.7651  7.1400 -7.7242 -7.7535  1.2316\n",
       "  -3.1121  8.0928 -6.7181  0.3397  6.5646\n",
       "   4.7795 -7.6468 -0.0241  1.1698 -0.9820\n",
       "   3.9628  4.0427 -2.8534  7.2310 -3.5860\n",
       "  -1.2484 -0.3620  4.6414  3.9096 -3.2002\n",
       " \n",
       " (15,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -1.6007  4.0613 -0.7086  3.8018  1.8857\n",
       "   5.2038  1.8887  2.9333  5.1184  6.8449\n",
       "   0.4775 -0.8208 -1.5069  5.6450  7.4366\n",
       "  -6.2898 -4.1053  1.1070  5.3023  7.4329\n",
       "  -2.2488 -3.5924 -3.3965 -3.9430  1.7324\n",
       " \n",
       " (15,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   3.1434 -0.7408  5.0317 -4.4853 -0.8040\n",
       "  -1.5036  7.3122  3.6546  8.0579 -4.4203\n",
       "   7.0715  2.1946  2.8018  3.9916 -4.9476\n",
       "  -7.7490  1.6680  3.8351 -0.0025 -2.7167\n",
       "  -4.4472 -1.0646  2.5412  6.8270  3.6757\n",
       " \n",
       " (15,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -7.5681  6.5087 -2.0068  4.8231 -1.2054\n",
       "  -2.7618 -2.2714  5.9176  0.4967 -5.5667\n",
       "  -4.3897  0.9114  5.2398  4.9052  7.0696\n",
       "  -1.0301  3.0001 -6.8300  2.5575 -1.7475\n",
       "   6.9646 -6.3315  2.0555  4.9902  1.1398\n",
       " \n",
       " (15,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   8.1109 -2.7171  5.5705  5.0297  2.2053\n",
       "   0.4413  0.0206 -7.9832  4.3798  6.7062\n",
       "  -5.9049 -1.9261 -5.4982  0.2759  5.9430\n",
       "   2.6358  3.6660  3.4409  3.6532 -4.5340\n",
       "  -2.6690 -0.0253  7.5347 -3.7811 -0.9742\n",
       " [torch.FloatTensor of size 16x6x5x5], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  -7.6576\n",
       "  -1.3041\n",
       "  -7.3967\n",
       "  -3.0138\n",
       "   8.0357\n",
       "   3.5120\n",
       "   4.1474\n",
       "   4.9039\n",
       "   0.5592\n",
       "  -1.1009\n",
       "  -2.4692\n",
       "   1.1180\n",
       "  -0.1604\n",
       "   1.3350\n",
       "  -1.2112\n",
       "   0.6685\n",
       " [torch.FloatTensor of size 16], Parameter containing:\n",
       " -2.6247e-02 -2.9435e-02 -3.3305e-02  ...   3.9550e-02  4.2696e-02 -2.8033e-02\n",
       " -3.7535e-02  4.0095e-02 -3.5892e-02  ...  -6.4607e-03  8.0290e-04  3.4396e-02\n",
       "  2.5074e-02  1.2066e-02  4.2965e-02  ...  -1.4840e-02  2.8506e-02  1.6359e-02\n",
       "                 ...                   ⋱                   ...                \n",
       " -1.1157e-02 -1.6098e-02 -3.0759e-02  ...   1.1755e-02  2.4527e-02  5.5107e-03\n",
       "  2.3773e-02 -3.5788e-02  1.4474e-02  ...   3.6988e-03  4.7758e-02  2.1232e-02\n",
       "  2.3670e-02 -7.5078e-03  2.6274e-02  ...  -3.3589e-04 -3.0342e-02 -4.1145e-02\n",
       " [torch.FloatTensor of size 120x400], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "   2.1603\n",
       "   3.8703\n",
       "  -0.6730\n",
       "  -0.1505\n",
       "  -4.4145\n",
       "   1.5793\n",
       "   2.4708\n",
       "   3.9463\n",
       "  -0.4556\n",
       "   1.7606\n",
       "  -2.0960\n",
       "  -2.1375\n",
       "   2.6398\n",
       "   1.8911\n",
       "  -2.4238\n",
       "   3.1526\n",
       "  -3.3424\n",
       "  -0.4153\n",
       "  -1.1752\n",
       "   0.7797\n",
       "   2.8444\n",
       "   0.1817\n",
       "   4.3474\n",
       "  -1.6574\n",
       "   0.6115\n",
       "   4.5137\n",
       "  -0.8196\n",
       "   1.5845\n",
       "  -4.4597\n",
       "   4.1038\n",
       "  -3.3389\n",
       "   4.0492\n",
       "   0.9263\n",
       "  -4.8190\n",
       "   4.2369\n",
       "  -4.2658\n",
       "  -1.6346\n",
       "   1.0671\n",
       "  -0.0015\n",
       "  -1.8695\n",
       "  -3.9950\n",
       "   1.4973\n",
       "  -1.5072\n",
       "  -1.4192\n",
       "  -3.5358\n",
       "  -2.9811\n",
       "   4.3276\n",
       "  -1.3016\n",
       "   4.7270\n",
       "   4.1046\n",
       "  -1.2116\n",
       "  -4.9890\n",
       "   1.5940\n",
       "  -0.4950\n",
       "  -4.8004\n",
       "  -4.2188\n",
       "   0.9581\n",
       "  -1.6529\n",
       "  -2.8652\n",
       "   0.8248\n",
       "   1.1659\n",
       "   3.5228\n",
       "  -4.5098\n",
       "   4.1119\n",
       "   1.7484\n",
       "   2.7314\n",
       "   0.0294\n",
       "   2.6646\n",
       "   3.0569\n",
       "  -0.3288\n",
       "   3.7200\n",
       "  -2.7656\n",
       "   0.7275\n",
       "  -3.1420\n",
       "  -3.4306\n",
       "   0.1668\n",
       "  -3.4549\n",
       "  -1.9917\n",
       "  -3.0798\n",
       "  -0.3886\n",
       "  -2.5893\n",
       "  -2.4309\n",
       "  -4.3989\n",
       "   3.2940\n",
       "  -3.3064\n",
       "   0.1578\n",
       "   1.8030\n",
       "  -2.9094\n",
       "  -4.1892\n",
       "  -4.8578\n",
       "  -4.7373\n",
       "   1.7472\n",
       "  -4.7489\n",
       "   3.8340\n",
       "   3.3121\n",
       "  -2.0595\n",
       "   2.6678\n",
       "   1.0782\n",
       "   0.8425\n",
       "   1.3946\n",
       "  -0.1011\n",
       "   4.6790\n",
       "   3.0698\n",
       "   3.7282\n",
       "   0.9444\n",
       "  -4.2468\n",
       "  -3.0561\n",
       "  -1.9091\n",
       "  -0.9825\n",
       "  -2.6722\n",
       "   2.4031\n",
       "   0.4604\n",
       "   3.8117\n",
       "   1.3423\n",
       "  -4.3246\n",
       "   3.4757\n",
       "   0.1063\n",
       "   2.3858\n",
       "   0.1852\n",
       "  -1.1058\n",
       " [torch.FloatTensor of size 120], Parameter containing:\n",
       " 1.00000e-02 *\n",
       " -5.8362  3.6746 -8.6106  ...  -7.0296  1.4647 -8.5118\n",
       "  5.8906 -5.7573  6.5767  ...   1.6470  4.8965  2.9954\n",
       "  6.1452  9.0121  7.6499  ...   2.2650 -3.4686  6.0294\n",
       "           ...             ⋱             ...          \n",
       " -7.4963  2.5599 -7.0373  ...   1.9321 -5.1303 -1.1973\n",
       " -4.2855  4.3187 -7.9525  ...   1.4215 -0.9923 -3.0189\n",
       "  4.1670 -0.7434 -6.7947  ...  -2.2508 -1.4001  7.1928\n",
       " [torch.FloatTensor of size 84x120], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "   0.1381\n",
       "   1.4387\n",
       "   1.3448\n",
       "  -2.0253\n",
       "  -6.3922\n",
       "  -7.9175\n",
       "   2.0100\n",
       "  -4.0574\n",
       "   0.8679\n",
       "   2.9650\n",
       "  -0.9477\n",
       "  -8.9657\n",
       "  -7.5541\n",
       "  -4.2347\n",
       "  -8.9761\n",
       "  -0.4757\n",
       "   6.2897\n",
       "   2.4269\n",
       "  -5.2414\n",
       "  -8.8091\n",
       "  -8.8901\n",
       "   4.6680\n",
       "  -2.7188\n",
       "   6.7621\n",
       "  -7.5876\n",
       "   7.8982\n",
       "  -7.3127\n",
       "  -6.8524\n",
       "  -6.1877\n",
       "   6.8737\n",
       "  -0.6517\n",
       "   5.5434\n",
       "  -6.1655\n",
       "  -8.2671\n",
       "  -1.0425\n",
       "   0.1718\n",
       "   5.0889\n",
       "  -7.3522\n",
       "   7.0140\n",
       "   6.1474\n",
       "   3.4172\n",
       "   3.0522\n",
       "   6.5099\n",
       "  -0.8003\n",
       "  -5.7000\n",
       "   3.1724\n",
       "  -4.0873\n",
       "   4.4102\n",
       "   6.8950\n",
       "   8.4104\n",
       "  -4.0997\n",
       "   4.2922\n",
       "   3.0919\n",
       "  -4.6805\n",
       "  -1.3098\n",
       "  -1.5859\n",
       "   0.0613\n",
       "   2.7063\n",
       "   7.5359\n",
       "  -6.0046\n",
       "  -5.4194\n",
       "  -3.7772\n",
       "   8.2029\n",
       "  -2.5020\n",
       "  -7.8346\n",
       "  -8.6506\n",
       "   1.6053\n",
       "   4.3874\n",
       "   3.2816\n",
       "  -8.0216\n",
       "   6.8397\n",
       "   4.9564\n",
       "   3.0392\n",
       "   6.0053\n",
       "  -0.6328\n",
       "   8.4666\n",
       "  -1.5461\n",
       "   4.7800\n",
       "  -0.6947\n",
       "   3.1476\n",
       "  -3.4529\n",
       "   1.5055\n",
       "   7.4503\n",
       "   8.5690\n",
       " [torch.FloatTensor of size 84], Parameter containing:\n",
       " \n",
       " Columns 0 to 9 \n",
       " -0.0982 -0.0761  0.0490  0.0320  0.0632  0.0272  0.0600  0.0861  0.0375  0.0568\n",
       "  0.0854 -0.0415 -0.0601  0.0061  0.0362  0.0047  0.1040 -0.0946 -0.1027 -0.0235\n",
       "  0.0236  0.0087 -0.0711 -0.0781 -0.0380  0.0396 -0.0325 -0.0239 -0.0776 -0.1087\n",
       " -0.0873  0.0967  0.0148  0.0221 -0.0038 -0.0468 -0.0007  0.1021 -0.1026  0.0941\n",
       " -0.0186  0.1003  0.0449 -0.0961 -0.0469  0.0331 -0.0452  0.0337  0.1058  0.0502\n",
       "  0.0156  0.0818 -0.0780 -0.0774 -0.1017  0.0648  0.0937 -0.0575 -0.0556  0.1073\n",
       " -0.0454  0.0501  0.0709 -0.0647  0.0981  0.0045 -0.0677  0.0756 -0.0285  0.0612\n",
       "  0.0573  0.0978  0.0405  0.0271  0.0862 -0.0513  0.0520  0.0764 -0.0243 -0.0307\n",
       "  0.0666 -0.0853 -0.0404 -0.0335  0.0583  0.0744  0.0151  0.0414 -0.1020 -0.0100\n",
       " -0.0720 -0.0666  0.0703  0.0342 -0.0079  0.0797 -0.0476 -0.0819 -0.0569 -0.0952\n",
       " \n",
       " Columns 10 to 19 \n",
       "  0.0832 -0.0093  0.0192 -0.0481 -0.0857 -0.0394 -0.0042 -0.0746 -0.0658 -0.0462\n",
       " -0.1078  0.0658 -0.1017  0.0665 -0.0705  0.0157 -0.0376  0.0956  0.0905  0.0920\n",
       "  0.1034  0.0148 -0.0479 -0.0512 -0.0082 -0.0279 -0.0966 -0.0144  0.0652  0.0293\n",
       "  0.0869 -0.0355  0.0545 -0.0626  0.0109 -0.0532  0.0438 -0.0762  0.0691 -0.0018\n",
       " -0.0040 -0.0614  0.0412  0.0558  0.0003 -0.0834 -0.0995  0.0926 -0.0366 -0.0508\n",
       " -0.0079 -0.0964 -0.0922  0.0722 -0.0280 -0.0380  0.0560  0.0414  0.0660  0.0661\n",
       " -0.0554  0.1002 -0.0267  0.0266 -0.0962  0.0903 -0.0146 -0.0762  0.0759 -0.0084\n",
       "  0.0159  0.0116  0.0147 -0.1026 -0.0857 -0.0686 -0.0441 -0.0660  0.0396  0.0659\n",
       " -0.0591  0.0800 -0.1042  0.1012 -0.0130 -0.0724  0.0531 -0.0829 -0.1021  0.0195\n",
       " -0.0477  0.0317  0.0402 -0.0493 -0.0752 -0.0379  0.0136  0.0609 -0.0581 -0.0872\n",
       " \n",
       " Columns 20 to 29 \n",
       "  0.1024  0.0766  0.0828 -0.0163 -0.0796  0.0597 -0.0830 -0.0550  0.0341  0.0750\n",
       " -0.0500 -0.0635 -0.0033 -0.0788 -0.0602 -0.0187 -0.0102 -0.0564  0.0920 -0.0556\n",
       " -0.0439  0.0670  0.0918  0.0316  0.0503 -0.0245  0.0307  0.1030  0.0240 -0.0725\n",
       " -0.1074 -0.0373  0.1069  0.1037  0.0697  0.0326  0.0305  0.0837  0.0869  0.0830\n",
       "  0.0931 -0.1019  0.1006 -0.0211  0.0031 -0.0934  0.0346 -0.0828 -0.0698 -0.0323\n",
       "  0.0507  0.0444 -0.0087  0.1071  0.0426 -0.1017 -0.0650 -0.0640  0.0682  0.0028\n",
       " -0.0631 -0.0139 -0.0047  0.1035 -0.0534 -0.0489  0.0935 -0.0330  0.0951  0.0655\n",
       " -0.0363  0.0419  0.0454 -0.0095 -0.0912 -0.0932 -0.0854  0.0463 -0.0242  0.0731\n",
       " -0.0551  0.1006  0.0044 -0.0411  0.0981 -0.0719 -0.0912  0.0922  0.0454  0.0734\n",
       " -0.0548 -0.0623 -0.1003  0.0255  0.0387  0.0057 -0.0767 -0.0358 -0.0622 -0.0290\n",
       " \n",
       " Columns 30 to 39 \n",
       " -0.0197  0.0885 -0.0332  0.0558  0.0168 -0.0799 -0.0235  0.0653 -0.0736  0.0212\n",
       " -0.0985 -0.0096 -0.0793 -0.0853  0.0269 -0.1031  0.0677 -0.0179 -0.0397  0.1057\n",
       "  0.0903 -0.0603  0.0657 -0.0722  0.0896 -0.1074  0.0277 -0.0496  0.0963  0.0207\n",
       "  0.0656  0.0002  0.0357  0.0644  0.0549 -0.0295  0.0234  0.0189 -0.0726  0.0474\n",
       " -0.0554 -0.0998 -0.0737 -0.0025 -0.0467 -0.0473 -0.0817 -0.0186  0.0409  0.0989\n",
       "  0.0207  0.0905  0.0401 -0.0640 -0.0977  0.0820  0.0601  0.1008  0.0181  0.0394\n",
       "  0.0735  0.0483 -0.0016  0.0857  0.0834 -0.0749  0.0658 -0.0678  0.0649  0.0894\n",
       "  0.0387  0.0525 -0.0523 -0.0380 -0.0505 -0.1082 -0.1032  0.1075 -0.0787  0.0651\n",
       "  0.0122 -0.0616 -0.1029 -0.0939 -0.0385  0.0793 -0.0955 -0.0476 -0.0732 -0.0920\n",
       " -0.0622  0.0792  0.0999  0.1010 -0.0500  0.0325 -0.0945 -0.0942 -0.0208  0.0340\n",
       " \n",
       " Columns 40 to 49 \n",
       "  0.0420  0.0094 -0.0853 -0.0099 -0.0501 -0.0537  0.0474 -0.0686  0.0560 -0.0665\n",
       " -0.0304 -0.0342  0.0543  0.0043 -0.0331 -0.1075  0.0716  0.0724  0.0055  0.0892\n",
       "  0.0427 -0.0894 -0.0608  0.0890  0.0183 -0.0605 -0.0797  0.0755 -0.0708 -0.0808\n",
       "  0.0237 -0.1059  0.0519  0.0910  0.1076  0.0949 -0.0117  0.0075  0.1043 -0.0202\n",
       "  0.0886 -0.0397  0.0777 -0.0927  0.0801 -0.0536  0.0162  0.0341  0.0366  0.0516\n",
       " -0.0844 -0.0667  0.0343 -0.0934 -0.0065  0.0475 -0.0736 -0.0270  0.0968  0.0485\n",
       "  0.0271  0.0923 -0.0521  0.0641 -0.0780 -0.0326  0.0427  0.1051  0.0888  0.0792\n",
       "  0.0302  0.0084 -0.0006  0.1075  0.0325  0.0347 -0.0467 -0.0164  0.0497  0.0336\n",
       " -0.0056 -0.0481  0.0796 -0.1049  0.0369  0.0007 -0.0126  0.0510  0.0677 -0.0770\n",
       " -0.0656 -0.0769  0.1014 -0.0195  0.1063  0.0919  0.0319  0.0882  0.0707  0.0662\n",
       " \n",
       " Columns 50 to 59 \n",
       " -0.0898  0.0222 -0.0165 -0.0574 -0.0391  0.0760 -0.0591  0.0851  0.0843  0.0293\n",
       "  0.0473  0.0423 -0.0072  0.0068 -0.0325  0.0228 -0.0146 -0.0179  0.0259  0.0502\n",
       "  0.1029 -0.0898 -0.1027  0.0401  0.0174  0.0685  0.0942  0.0422  0.0695  0.0945\n",
       "  0.0579  0.0305  0.0700 -0.0456  0.1046  0.0024  0.1090  0.0619  0.0648  0.0371\n",
       " -0.0207 -0.0821  0.0627 -0.0414 -0.0562  0.0962 -0.0952 -0.0399 -0.0429 -0.0551\n",
       "  0.0775  0.0467 -0.0598 -0.0838 -0.0691 -0.1091  0.0985 -0.1029 -0.0761  0.0870\n",
       "  0.0637  0.0399  0.1008  0.0553  0.0168  0.0234  0.0586 -0.0777  0.0594 -0.0464\n",
       "  0.0542  0.0492 -0.0863  0.0332  0.0485  0.0847 -0.0970 -0.0133 -0.0550  0.0393\n",
       " -0.0494 -0.0001 -0.0702 -0.0570 -0.0106  0.0758 -0.0870  0.0396 -0.0911  0.0759\n",
       "  0.0715 -0.0929  0.0155  0.0352  0.1000  0.0093 -0.1034  0.0336 -0.0186 -0.0989\n",
       " \n",
       " Columns 60 to 69 \n",
       " -0.0055  0.0558  0.0677  0.0761  0.0945  0.0943 -0.0823 -0.0330  0.0239  0.0886\n",
       "  0.1063 -0.0112  0.0874  0.0723 -0.0795 -0.0580 -0.0859 -0.0016  0.0251  0.0529\n",
       "  0.0234  0.0263  0.0597 -0.0865 -0.0295 -0.0463  0.0297 -0.0449 -0.0459  0.0707\n",
       " -0.0298 -0.0441  0.0808 -0.0327 -0.0887  0.0458 -0.0746 -0.0214 -0.0104  0.0249\n",
       "  0.0971  0.1050  0.0138 -0.0444  0.0539  0.0604 -0.0331  0.0290  0.0833 -0.0457\n",
       "  0.0800  0.0790 -0.0329 -0.0823 -0.1032  0.0081  0.1080 -0.0799  0.0091  0.0279\n",
       "  0.1071 -0.0205  0.0105 -0.0545 -0.0432  0.1033 -0.0013  0.0339 -0.0661 -0.0501\n",
       " -0.0468 -0.0311 -0.0404  0.0132  0.0942  0.0886 -0.0385  0.0255  0.0676  0.0759\n",
       " -0.0696 -0.0160 -0.0034  0.0359 -0.1007 -0.0176  0.0465 -0.0269 -0.0024 -0.0283\n",
       " -0.0835 -0.0137 -0.0495 -0.0583  0.0168  0.0095 -0.0170 -0.0097 -0.0562 -0.0517\n",
       " \n",
       " Columns 70 to 79 \n",
       " -0.0425 -0.0137  0.0148  0.0909 -0.1061  0.0640 -0.0161 -0.0756 -0.0878 -0.0089\n",
       " -0.1081 -0.0388 -0.0968  0.0560 -0.0430 -0.0434  0.0474  0.0475  0.0081 -0.0609\n",
       "  0.0332  0.0280 -0.1006 -0.0650  0.0705  0.0064 -0.0457  0.0326  0.0446 -0.0487\n",
       "  0.0868  0.0398  0.0519  0.0768  0.1041  0.0192  0.0799  0.0223  0.0475  0.0535\n",
       " -0.0822  0.0505 -0.0849 -0.0589 -0.0135  0.0842 -0.0675  0.0568 -0.0816  0.0446\n",
       "  0.0654  0.0029  0.0123  0.0151  0.0813 -0.0708  0.0775  0.0836 -0.0429  0.0514\n",
       "  0.0902  0.0471 -0.0825  0.1033  0.0410  0.0888 -0.0705  0.1030 -0.0614  0.0201\n",
       "  0.0888  0.0544  0.0803 -0.0130  0.0653  0.0008 -0.0653 -0.0318 -0.0254 -0.0017\n",
       "  0.0376  0.0531  0.0087 -0.0382 -0.0797  0.0447 -0.0312  0.0987 -0.0595  0.0095\n",
       "  0.0906 -0.0697 -0.0417  0.1028 -0.0771  0.0840 -0.1079 -0.0220  0.0590 -0.0789\n",
       " \n",
       " Columns 80 to 83 \n",
       "  0.0859 -0.0907 -0.0970  0.0614\n",
       "  0.0473 -0.0306 -0.0865  0.0682\n",
       "  0.0984  0.1021  0.0437  0.0926\n",
       " -0.0402  0.0079 -0.0112 -0.0905\n",
       "  0.0981  0.0201  0.0567 -0.0701\n",
       "  0.0975  0.0396 -0.0463 -0.0227\n",
       "  0.0358 -0.0540  0.0450 -0.0621\n",
       "  0.0311 -0.0481 -0.0501 -0.0263\n",
       " -0.0255 -0.1001 -0.0592  0.0063\n",
       " -0.0096 -0.0759  0.1087  0.0432\n",
       " [torch.FloatTensor of size 10x84], Parameter containing:\n",
       " -0.0776\n",
       " -0.1054\n",
       "  0.0256\n",
       "  0.0107\n",
       " -0.0748\n",
       "  0.0755\n",
       " -0.0004\n",
       " -0.0301\n",
       "  0.0935\n",
       "  0.0924\n",
       " [torch.FloatTensor of size 10]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 400])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# list the size of each param\n",
    "for para in list(net.parameters()):\n",
    "    print(para.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
