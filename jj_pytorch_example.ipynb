{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm-up: numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 35085673.5744\n",
      "1 29152320.9546\n",
      "2 25719684.9325\n",
      "3 21270186.6668\n",
      "4 15828714.7687\n",
      "5 10572329.3388\n",
      "6 6660169.42016\n",
      "7 4150003.44604\n",
      "8 2689480.4031\n",
      "9 1852591.94893\n",
      "10 1362372.1164\n",
      "11 1057579.53626\n",
      "12 854921.702839\n",
      "13 710857.047815\n",
      "14 602503.819072\n",
      "15 517260.634328\n",
      "16 448319.045746\n",
      "17 391324.169916\n",
      "18 343486.084949\n",
      "19 302922.148328\n",
      "20 268182.948197\n",
      "21 238225.751713\n",
      "22 212271.752935\n",
      "23 189697.833477\n",
      "24 169976.02322\n",
      "25 152683.956417\n",
      "26 137453.510157\n",
      "27 123994.015395\n",
      "28 112067.220889\n",
      "29 101474.947068\n",
      "30 92042.8291108\n",
      "31 83628.9427811\n",
      "32 76110.6034995\n",
      "33 69369.4931511\n",
      "34 63318.9071856\n",
      "35 57870.2845482\n",
      "36 52956.6638644\n",
      "37 48522.3325789\n",
      "38 44508.474197\n",
      "39 40868.8768494\n",
      "40 37564.6362527\n",
      "41 34562.134672\n",
      "42 31830.8405168\n",
      "43 29343.3164225\n",
      "44 27074.5845803\n",
      "45 25001.5573751\n",
      "46 23105.9826738\n",
      "47 21370.7079083\n",
      "48 19780.0159832\n",
      "49 18320.6785824\n",
      "50 16980.6690085\n",
      "51 15748.8715034\n",
      "52 14615.9564306\n",
      "53 13572.6996569\n",
      "54 12611.3042657\n",
      "55 11724.9292348\n",
      "56 10906.865741\n",
      "57 10151.9246323\n",
      "58 9453.95090619\n",
      "59 8808.66967981\n",
      "60 8211.98599825\n",
      "61 7659.38776285\n",
      "62 7147.38001318\n",
      "63 6672.33577496\n",
      "64 6231.6873871\n",
      "65 5822.8773984\n",
      "66 5442.89642134\n",
      "67 5089.6322764\n",
      "68 4761.08766015\n",
      "69 4455.59668127\n",
      "70 4171.28967105\n",
      "71 3906.54361015\n",
      "72 3659.79514148\n",
      "73 3429.92875312\n",
      "74 3215.37612177\n",
      "75 3015.16381343\n",
      "76 2828.3594969\n",
      "77 2653.93470646\n",
      "78 2490.92430541\n",
      "79 2338.65117809\n",
      "80 2196.31068706\n",
      "81 2063.16227577\n",
      "82 1938.62477236\n",
      "83 1821.98583686\n",
      "84 1712.82669237\n",
      "85 1610.62252899\n",
      "86 1514.84712887\n",
      "87 1425.1371582\n",
      "88 1341.03871979\n",
      "89 1262.17002862\n",
      "90 1188.21220062\n",
      "91 1118.81436331\n",
      "92 1053.68390645\n",
      "93 992.543471206\n",
      "94 935.160872996\n",
      "95 881.244499153\n",
      "96 830.600066962\n",
      "97 783.003082734\n",
      "98 738.283751207\n",
      "99 696.250280269\n",
      "100 656.730915429\n",
      "101 619.562130506\n",
      "102 584.585098728\n",
      "103 551.669936814\n",
      "104 520.703362479\n",
      "105 491.559184389\n",
      "106 464.120698093\n",
      "107 438.295955858\n",
      "108 413.958656195\n",
      "109 391.037362456\n",
      "110 369.440791216\n",
      "111 349.088292301\n",
      "112 329.905698122\n",
      "113 311.831437219\n",
      "114 294.786650247\n",
      "115 278.708672757\n",
      "116 263.556889154\n",
      "117 249.274542776\n",
      "118 235.800474507\n",
      "119 223.085833698\n",
      "120 211.081334935\n",
      "121 199.749152679\n",
      "122 189.048108206\n",
      "123 178.946420314\n",
      "124 169.403242532\n",
      "125 160.40302443\n",
      "126 151.896315924\n",
      "127 143.860053566\n",
      "128 136.264409911\n",
      "129 129.083813034\n",
      "130 122.298615941\n",
      "131 115.883219798\n",
      "132 109.817926089\n",
      "133 104.07964125\n",
      "134 98.651698213\n",
      "135 93.5179730454\n",
      "136 88.6630995304\n",
      "137 84.0679979242\n",
      "138 79.7196425008\n",
      "139 75.6036070006\n",
      "140 71.708013083\n",
      "141 68.018051194\n",
      "142 64.5250455738\n",
      "143 61.2177657278\n",
      "144 58.0858321032\n",
      "145 55.1207028197\n",
      "146 52.3125196728\n",
      "147 49.652578237\n",
      "148 47.1319740551\n",
      "149 44.7440774155\n",
      "150 42.4811837053\n",
      "151 40.337416513\n",
      "152 38.3055514091\n",
      "153 36.3791406028\n",
      "154 34.5531264037\n",
      "155 32.823862119\n",
      "156 31.1846098197\n",
      "157 29.6299821364\n",
      "158 28.1551136049\n",
      "159 26.756352965\n",
      "160 25.4294127752\n",
      "161 24.1710893716\n",
      "162 22.9768823331\n",
      "163 21.8434831218\n",
      "164 20.7678958627\n",
      "165 19.7473392613\n",
      "166 18.779105812\n",
      "167 17.8594129252\n",
      "168 16.9862868406\n",
      "169 16.1572645788\n",
      "170 15.3702704611\n",
      "171 14.6230577199\n",
      "172 13.9131434103\n",
      "173 13.2388516371\n",
      "174 12.5982763765\n",
      "175 11.990007553\n",
      "176 11.4121856033\n",
      "177 10.8629034528\n",
      "178 10.3410161296\n",
      "179 9.84498495322\n",
      "180 9.37385370267\n",
      "181 8.9257854893\n",
      "182 8.49986209177\n",
      "183 8.09498739345\n",
      "184 7.71008953449\n",
      "185 7.34412411858\n",
      "186 6.99607389582\n",
      "187 6.66506126714\n",
      "188 6.3502415724\n",
      "189 6.05092965023\n",
      "190 5.76611951452\n",
      "191 5.4951302258\n",
      "192 5.23731397594\n",
      "193 4.99205823025\n",
      "194 4.75860994276\n",
      "195 4.53644642968\n",
      "196 4.32500580964\n",
      "197 4.12379198964\n",
      "198 3.93225408251\n",
      "199 3.74990276584\n",
      "200 3.57632872323\n",
      "201 3.41102123947\n",
      "202 3.25365643566\n",
      "203 3.10374788531\n",
      "204 2.96095624233\n",
      "205 2.82497461583\n",
      "206 2.6955107698\n",
      "207 2.5721213482\n",
      "208 2.4545852783\n",
      "209 2.34260147082\n",
      "210 2.235929643\n",
      "211 2.13423765308\n",
      "212 2.03732624383\n",
      "213 1.94496480422\n",
      "214 1.85698595796\n",
      "215 1.77309345944\n",
      "216 1.69309695905\n",
      "217 1.61682932287\n",
      "218 1.54414764063\n",
      "219 1.47480983909\n",
      "220 1.40869178055\n",
      "221 1.34563170969\n",
      "222 1.28552322224\n",
      "223 1.22815627302\n",
      "224 1.17343241882\n",
      "225 1.12123545758\n",
      "226 1.07145437322\n",
      "227 1.02393882468\n",
      "228 0.978597203071\n",
      "229 0.935339155148\n",
      "230 0.894071001293\n",
      "231 0.854664334013\n",
      "232 0.817053203976\n",
      "233 0.78115767298\n",
      "234 0.746891693802\n",
      "235 0.714167989195\n",
      "236 0.682924132275\n",
      "237 0.653098537079\n",
      "238 0.624620672056\n",
      "239 0.597418860904\n",
      "240 0.571439095481\n",
      "241 0.546634894878\n",
      "242 0.522933064707\n",
      "243 0.500292267366\n",
      "244 0.47866713041\n",
      "245 0.458010617413\n",
      "246 0.438265861113\n",
      "247 0.419399013541\n",
      "248 0.401376678937\n",
      "249 0.384151877073\n",
      "250 0.367689927924\n",
      "251 0.351952384599\n",
      "252 0.33691606501\n",
      "253 0.322535207665\n",
      "254 0.308788260148\n",
      "255 0.295648148449\n",
      "256 0.283087880534\n",
      "257 0.271073208594\n",
      "258 0.259582953617\n",
      "259 0.248599769306\n",
      "260 0.238092639329\n",
      "261 0.228041980466\n",
      "262 0.218431179132\n",
      "263 0.209238301058\n",
      "264 0.200441744002\n",
      "265 0.192025695549\n",
      "266 0.183977600237\n",
      "267 0.176273798065\n",
      "268 0.168903829775\n",
      "269 0.161852207508\n",
      "270 0.155102482722\n",
      "271 0.148641225472\n",
      "272 0.142457807301\n",
      "273 0.136540682875\n",
      "274 0.130874474994\n",
      "275 0.125450368313\n",
      "276 0.120259292101\n",
      "277 0.115288245405\n",
      "278 0.110527984318\n",
      "279 0.105971105287\n",
      "280 0.101607965309\n",
      "281 0.0974281749927\n",
      "282 0.0934252636716\n",
      "283 0.0895930475387\n",
      "284 0.0859208948999\n",
      "285 0.0824037195763\n",
      "286 0.0790353709945\n",
      "287 0.0758080611442\n",
      "288 0.072715843162\n",
      "289 0.069753615891\n",
      "290 0.0669157528226\n",
      "291 0.0641958016643\n",
      "292 0.0615894915417\n",
      "293 0.0590926613614\n",
      "294 0.0566987718087\n",
      "295 0.0544045429727\n",
      "296 0.0522065925807\n",
      "297 0.0500989834009\n",
      "298 0.0480788292669\n",
      "299 0.0461427453234\n",
      "300 0.0442862508471\n",
      "301 0.0425062721708\n",
      "302 0.0408000213662\n",
      "303 0.0391638787425\n",
      "304 0.0375947245181\n",
      "305 0.0360903936771\n",
      "306 0.0346477882949\n",
      "307 0.0332640188173\n",
      "308 0.0319370353452\n",
      "309 0.0306645624904\n",
      "310 0.0294437904781\n",
      "311 0.0282727711539\n",
      "312 0.0271497426888\n",
      "313 0.026072061431\n",
      "314 0.0250382016008\n",
      "315 0.0240467381507\n",
      "316 0.0230950472301\n",
      "317 0.0221819201355\n",
      "318 0.0213061196822\n",
      "319 0.0204654238083\n",
      "320 0.0196586325631\n",
      "321 0.0188846755653\n",
      "322 0.0181415810333\n",
      "323 0.0174284198056\n",
      "324 0.0167441922082\n",
      "325 0.0160871562049\n",
      "326 0.0154564895489\n",
      "327 0.0148513708678\n",
      "328 0.0142702565157\n",
      "329 0.013712344071\n",
      "330 0.0131769566557\n",
      "331 0.0126627051866\n",
      "332 0.0121689556492\n",
      "333 0.0116950181899\n",
      "334 0.011239774692\n",
      "335 0.0108026440931\n",
      "336 0.0103830973063\n",
      "337 0.00997993211695\n",
      "338 0.00959276992385\n",
      "339 0.00922105673838\n",
      "340 0.00886390634501\n",
      "341 0.00852089993028\n",
      "342 0.00819151642346\n",
      "343 0.00787502074879\n",
      "344 0.00757103503802\n",
      "345 0.00727904718663\n",
      "346 0.00699846142172\n",
      "347 0.00672894664913\n",
      "348 0.00647002783105\n",
      "349 0.00622120172137\n",
      "350 0.00598217492652\n",
      "351 0.00575251699107\n",
      "352 0.00553178593084\n",
      "353 0.00531972652278\n",
      "354 0.00511592930212\n",
      "355 0.00492005789175\n",
      "356 0.00473186850787\n",
      "357 0.00455097176776\n",
      "358 0.00437710661822\n",
      "359 0.0042100502548\n",
      "360 0.00404942957168\n",
      "361 0.00389504809631\n",
      "362 0.00374669266239\n",
      "363 0.00360404239141\n",
      "364 0.00346693317758\n",
      "365 0.00333514205882\n",
      "366 0.00320841334277\n",
      "367 0.00308660642406\n",
      "368 0.00296949446694\n",
      "369 0.00285687696757\n",
      "370 0.00274863676581\n",
      "371 0.00264454208972\n",
      "372 0.00254443759764\n",
      "373 0.00244821707706\n",
      "374 0.00235566035295\n",
      "375 0.00226666152766\n",
      "376 0.00218109517731\n",
      "377 0.00209879008661\n",
      "378 0.00201964438292\n",
      "379 0.00194352960073\n",
      "380 0.00187031453495\n",
      "381 0.00179991527403\n",
      "382 0.00173219570426\n",
      "383 0.00166705483639\n",
      "384 0.00160441827166\n",
      "385 0.00154414853222\n",
      "386 0.00148618115585\n",
      "387 0.00143042697299\n",
      "388 0.00137678221171\n",
      "389 0.00132518732082\n",
      "390 0.00127554647275\n",
      "391 0.00122778576885\n",
      "392 0.00118185281785\n",
      "393 0.00113764802896\n",
      "394 0.00109512006515\n",
      "395 0.00105420880211\n",
      "396 0.00101483569466\n",
      "397 0.000976961711615\n",
      "398 0.000940515388509\n",
      "399 0.00090544194176\n",
      "400 0.00087170210709\n",
      "401 0.000839225987874\n",
      "402 0.00080797836783\n",
      "403 0.000777911208797\n",
      "404 0.000748969423177\n",
      "405 0.000721126127453\n",
      "406 0.00069432496598\n",
      "407 0.00066853103921\n",
      "408 0.000643710853987\n",
      "409 0.00061981683818\n",
      "410 0.000596823507113\n",
      "411 0.000574693085865\n",
      "412 0.000553388735529\n",
      "413 0.000532889441076\n",
      "414 0.000513152010931\n",
      "415 0.000494155682921\n",
      "416 0.000475871574537\n",
      "417 0.000458267810715\n",
      "418 0.00044132658791\n",
      "419 0.000425015039033\n",
      "420 0.000409313369722\n",
      "421 0.000394199381396\n",
      "422 0.000379646336337\n",
      "423 0.000365639019041\n",
      "424 0.00035215202103\n",
      "425 0.000339167012159\n",
      "426 0.000326667600794\n",
      "427 0.000314631007414\n",
      "428 0.000303044319146\n",
      "429 0.00029188732383\n",
      "430 0.000281144882992\n",
      "431 0.000270803297865\n",
      "432 0.000260842992661\n",
      "433 0.000251254306296\n",
      "434 0.000242020714803\n",
      "435 0.000233128894583\n",
      "436 0.000224568653447\n",
      "437 0.000216323276652\n",
      "438 0.000208384971519\n",
      "439 0.000200739777167\n",
      "440 0.000193377055143\n",
      "441 0.000186288465089\n",
      "442 0.000179459907013\n",
      "443 0.000172885560249\n",
      "444 0.000166553288935\n",
      "445 0.000160454253023\n",
      "446 0.000154581846489\n",
      "447 0.000148924546422\n",
      "448 0.000143477075664\n",
      "449 0.000138229997954\n",
      "450 0.000133176066323\n",
      "451 0.000128309292798\n",
      "452 0.000123620642622\n",
      "453 0.000119105546088\n",
      "454 0.000114756157114\n",
      "455 0.00011056674419\n",
      "456 0.0001065319204\n",
      "457 0.000102644709559\n",
      "458 9.8901171591e-05\n",
      "459 9.52945520586e-05\n",
      "460 9.18206570324e-05\n",
      "461 8.84744024765e-05\n",
      "462 8.52505498823e-05\n",
      "463 8.21457313421e-05\n",
      "464 7.9154032877e-05\n",
      "465 7.6272495827e-05\n",
      "466 7.34964567188e-05\n",
      "467 7.08219361709e-05\n",
      "468 6.82459085808e-05\n",
      "469 6.57635874788e-05\n",
      "470 6.33726687415e-05\n",
      "471 6.10689552842e-05\n",
      "472 5.88495249665e-05\n",
      "473 5.67115419676e-05\n",
      "474 5.46512784474e-05\n",
      "475 5.26668684881e-05\n",
      "476 5.07545248632e-05\n",
      "477 4.89122591677e-05\n",
      "478 4.71372752985e-05\n",
      "479 4.54269142838e-05\n",
      "480 4.37793891366e-05\n",
      "481 4.21915818048e-05\n",
      "482 4.06619569158e-05\n",
      "483 3.91879202345e-05\n",
      "484 3.77676960967e-05\n",
      "485 3.63992959772e-05\n",
      "486 3.50805694142e-05\n",
      "487 3.38102102233e-05\n",
      "488 3.25857908982e-05\n",
      "489 3.14061713643e-05\n",
      "490 3.02693888238e-05\n",
      "491 2.91739479625e-05\n",
      "492 2.81185162465e-05\n",
      "493 2.71012535196e-05\n",
      "494 2.61212315636e-05\n",
      "495 2.51766357135e-05\n",
      "496 2.42664749491e-05\n",
      "497 2.33893663947e-05\n",
      "498 2.25440808174e-05\n",
      "499 2.17296019018e-05\n"
     ]
    }
   ],
   "source": [
    "# Code in file tensor/two_layer_net_numpy.py\n",
    "import numpy as np\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    #Forward pass: compute predicted y\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "    \n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(t, loss)\n",
    "    \n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "\n",
    "    # Update weights\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 41882532.0\n",
      "1 41397944.0\n",
      "2 40370916.0\n",
      "3 32229242.0\n",
      "4 19835026.0\n",
      "5 9919456.0\n",
      "6 4810091.5\n",
      "7 2645262.5\n",
      "8 1731744.5\n",
      "9 1286385.375\n",
      "10 1024079.125\n",
      "11 843522.5\n",
      "12 707276.625\n",
      "13 599408.4375\n",
      "14 511876.625\n",
      "15 439779.4375\n",
      "16 379860.71875\n",
      "17 329624.125\n",
      "18 287365.15625\n",
      "19 251542.46875\n",
      "20 220984.296875\n",
      "21 194766.515625\n",
      "22 172166.96875\n",
      "23 152602.875\n",
      "24 135611.3125\n",
      "25 120805.390625\n",
      "26 107876.8203125\n",
      "27 96535.640625\n",
      "28 86562.8515625\n",
      "29 77771.3515625\n",
      "30 70000.265625\n",
      "31 63109.96875\n",
      "32 56993.0234375\n",
      "33 51549.625\n",
      "34 46697.6484375\n",
      "35 42366.55859375\n",
      "36 38490.48828125\n",
      "37 35016.59765625\n",
      "38 31900.232421875\n",
      "39 29098.12890625\n",
      "40 26581.78125\n",
      "41 24312.78515625\n",
      "42 22263.216796875\n",
      "43 20408.951171875\n",
      "44 18729.52734375\n",
      "45 17207.3515625\n",
      "46 15824.5859375\n",
      "47 14567.6728515625\n",
      "48 13423.7607421875\n",
      "49 12381.3994140625\n",
      "50 11430.263671875\n",
      "51 10561.7255859375\n",
      "52 9768.1044921875\n",
      "53 9042.0576171875\n",
      "54 8376.904296875\n",
      "55 7767.08203125\n",
      "56 7208.009765625\n",
      "57 6694.4599609375\n",
      "58 6222.5556640625\n",
      "59 5788.0595703125\n",
      "60 5387.8486328125\n",
      "61 5018.88671875\n",
      "62 4678.482421875\n",
      "63 4364.23583984375\n",
      "64 4073.919921875\n",
      "65 3805.3740234375\n",
      "66 3556.70556640625\n",
      "67 3326.458740234375\n",
      "68 3112.979248046875\n",
      "69 2914.99169921875\n",
      "70 2731.24951171875\n",
      "71 2560.700439453125\n",
      "72 2402.177001953125\n",
      "73 2254.81103515625\n",
      "74 2117.63818359375\n",
      "75 1990.0126953125\n",
      "76 1870.9769287109375\n",
      "77 1759.9949951171875\n",
      "78 1656.3778076171875\n",
      "79 1559.6214599609375\n",
      "80 1469.1993408203125\n",
      "81 1384.701904296875\n",
      "82 1305.6317138671875\n",
      "83 1231.6077880859375\n",
      "84 1162.2928466796875\n",
      "85 1097.33349609375\n",
      "86 1036.4534912109375\n",
      "87 979.3526611328125\n",
      "88 925.7417602539062\n",
      "89 875.386962890625\n",
      "90 828.1038208007812\n",
      "91 783.6500854492188\n",
      "92 741.8545532226562\n",
      "93 702.532470703125\n",
      "94 665.5120239257812\n",
      "95 630.6666870117188\n",
      "96 597.8447875976562\n",
      "97 566.8928833007812\n",
      "98 537.7183837890625\n",
      "99 510.186767578125\n",
      "100 484.23028564453125\n",
      "101 459.7143249511719\n",
      "102 436.5552673339844\n",
      "103 414.67333984375\n",
      "104 393.9988708496094\n",
      "105 374.4626770019531\n",
      "106 355.96282958984375\n",
      "107 338.4632873535156\n",
      "108 321.90765380859375\n",
      "109 306.23919677734375\n",
      "110 291.3869323730469\n",
      "111 277.3251037597656\n",
      "112 263.99908447265625\n",
      "113 251.35394287109375\n",
      "114 239.37106323242188\n",
      "115 227.99960327148438\n",
      "116 217.21339416503906\n",
      "117 206.973388671875\n",
      "118 197.2589569091797\n",
      "119 188.0311737060547\n",
      "120 179.26390075683594\n",
      "121 170.93251037597656\n",
      "122 163.01751708984375\n",
      "123 155.49343872070312\n",
      "124 148.3382110595703\n",
      "125 141.53555297851562\n",
      "126 135.06674194335938\n",
      "127 128.9223175048828\n",
      "128 123.08145141601562\n",
      "129 117.5224609375\n",
      "130 112.23240661621094\n",
      "131 107.19628143310547\n",
      "132 102.3971176147461\n",
      "133 97.82930755615234\n",
      "134 93.47299194335938\n",
      "135 89.32386779785156\n",
      "136 85.36970520019531\n",
      "137 81.59859466552734\n",
      "138 78.0052261352539\n",
      "139 74.57564544677734\n",
      "140 71.30695343017578\n",
      "141 68.18550109863281\n",
      "142 65.20816040039062\n",
      "143 62.37092208862305\n",
      "144 59.66082000732422\n",
      "145 57.07253646850586\n",
      "146 54.60321044921875\n",
      "147 52.245609283447266\n",
      "148 49.99385452270508\n",
      "149 47.84390640258789\n",
      "150 45.788612365722656\n",
      "151 43.82667541503906\n",
      "152 41.95392608642578\n",
      "153 40.16270065307617\n",
      "154 38.4513053894043\n",
      "155 36.81595230102539\n",
      "156 35.2527961730957\n",
      "157 33.75713348388672\n",
      "158 32.32826232910156\n",
      "159 30.962112426757812\n",
      "160 29.65630531311035\n",
      "161 28.406776428222656\n",
      "162 27.211620330810547\n",
      "163 26.067655563354492\n",
      "164 24.97354507446289\n",
      "165 23.927745819091797\n",
      "166 22.927001953125\n",
      "167 21.968915939331055\n",
      "168 21.051620483398438\n",
      "169 20.17572021484375\n",
      "170 19.334518432617188\n",
      "171 18.530982971191406\n",
      "172 17.76153564453125\n",
      "173 17.025056838989258\n",
      "174 16.319351196289062\n",
      "175 15.64457893371582\n",
      "176 14.997223854064941\n",
      "177 14.38016128540039\n",
      "178 13.788911819458008\n",
      "179 13.223337173461914\n",
      "180 12.681411743164062\n",
      "181 12.162027359008789\n",
      "182 11.664410591125488\n",
      "183 11.18741226196289\n",
      "184 10.730799674987793\n",
      "185 10.293537139892578\n",
      "186 9.873135566711426\n",
      "187 9.472306251525879\n",
      "188 9.087028503417969\n",
      "189 8.717727661132812\n",
      "190 8.363046646118164\n",
      "191 8.023628234863281\n",
      "192 7.698164939880371\n",
      "193 7.386687755584717\n",
      "194 7.087957859039307\n",
      "195 6.800964832305908\n",
      "196 6.526360034942627\n",
      "197 6.262706756591797\n",
      "198 6.009987831115723\n",
      "199 5.767690181732178\n",
      "200 5.535334587097168\n",
      "201 5.312621593475342\n",
      "202 5.098983287811279\n",
      "203 4.894308090209961\n",
      "204 4.697239398956299\n",
      "205 4.508724212646484\n",
      "206 4.327895164489746\n",
      "207 4.154102802276611\n",
      "208 3.9876749515533447\n",
      "209 3.827908515930176\n",
      "210 3.674901008605957\n",
      "211 3.527716636657715\n",
      "212 3.3868398666381836\n",
      "213 3.2515387535095215\n",
      "214 3.1218559741973877\n",
      "215 2.9972445964813232\n",
      "216 2.8775837421417236\n",
      "217 2.7630412578582764\n",
      "218 2.653014659881592\n",
      "219 2.5471653938293457\n",
      "220 2.445866584777832\n",
      "221 2.348741054534912\n",
      "222 2.2549171447753906\n",
      "223 2.165330648422241\n",
      "224 2.079299211502075\n",
      "225 1.9969069957733154\n",
      "226 1.9178398847579956\n",
      "227 1.841784119606018\n",
      "228 1.7688252925872803\n",
      "229 1.6986333131790161\n",
      "230 1.6313490867614746\n",
      "231 1.5667321681976318\n",
      "232 1.5044867992401123\n",
      "233 1.4449975490570068\n",
      "234 1.387799859046936\n",
      "235 1.3329358100891113\n",
      "236 1.2804428339004517\n",
      "237 1.2297676801681519\n",
      "238 1.18117094039917\n",
      "239 1.1345192193984985\n",
      "240 1.0899494886398315\n",
      "241 1.0470106601715088\n",
      "242 1.0057321786880493\n",
      "243 0.9659520387649536\n",
      "244 0.9277726411819458\n",
      "245 0.891387939453125\n",
      "246 0.8563774824142456\n",
      "247 0.8226022720336914\n",
      "248 0.7902249097824097\n",
      "249 0.7591647505760193\n",
      "250 0.7292421460151672\n",
      "251 0.7007163166999817\n",
      "252 0.6731930375099182\n",
      "253 0.6466298699378967\n",
      "254 0.6211252212524414\n",
      "255 0.5968146324157715\n",
      "256 0.5734806656837463\n",
      "257 0.5509675145149231\n",
      "258 0.5293210744857788\n",
      "259 0.508626401424408\n",
      "260 0.48868387937545776\n",
      "261 0.46955177187919617\n",
      "262 0.4512041509151459\n",
      "263 0.43353113532066345\n",
      "264 0.41651302576065063\n",
      "265 0.40027332305908203\n",
      "266 0.3845445513725281\n",
      "267 0.3694561719894409\n",
      "268 0.3550679683685303\n",
      "269 0.34121108055114746\n",
      "270 0.32790854573249817\n",
      "271 0.31508150696754456\n",
      "272 0.30274906754493713\n",
      "273 0.2909177541732788\n",
      "274 0.27956628799438477\n",
      "275 0.2686505913734436\n",
      "276 0.2582347095012665\n",
      "277 0.24813251197338104\n",
      "278 0.23843692243099213\n",
      "279 0.22918997704982758\n",
      "280 0.22030647099018097\n",
      "281 0.21162541210651398\n",
      "282 0.20342040061950684\n",
      "283 0.19546177983283997\n",
      "284 0.1878877580165863\n",
      "285 0.18058720231056213\n",
      "286 0.17355114221572876\n",
      "287 0.16671821475028992\n",
      "288 0.16028377413749695\n",
      "289 0.15400655567646027\n",
      "290 0.14802169799804688\n",
      "291 0.14224791526794434\n",
      "292 0.13671141862869263\n",
      "293 0.13141894340515137\n",
      "294 0.1263076663017273\n",
      "295 0.12138120085000992\n",
      "296 0.11673019826412201\n",
      "297 0.11222168058156967\n",
      "298 0.10779085755348206\n",
      "299 0.10359600186347961\n",
      "300 0.09959901869297028\n",
      "301 0.09572163224220276\n",
      "302 0.09201490879058838\n",
      "303 0.08842479437589645\n",
      "304 0.08501022309064865\n",
      "305 0.08172184973955154\n",
      "306 0.07857684046030045\n",
      "307 0.07553379237651825\n",
      "308 0.07260560989379883\n",
      "309 0.06979522854089737\n",
      "310 0.06705458462238312\n",
      "311 0.06449367851018906\n",
      "312 0.06197332590818405\n",
      "313 0.059559013694524765\n",
      "314 0.05725488439202309\n",
      "315 0.055033061653375626\n",
      "316 0.052924320101737976\n",
      "317 0.05089636147022247\n",
      "318 0.048934198915958405\n",
      "319 0.04704446718096733\n",
      "320 0.045222800225019455\n",
      "321 0.04348137602210045\n",
      "322 0.04181572049856186\n",
      "323 0.04023406654596329\n",
      "324 0.0386943519115448\n",
      "325 0.037185851484537125\n",
      "326 0.035747043788433075\n",
      "327 0.03436874598264694\n",
      "328 0.033035341650247574\n",
      "329 0.03176909312605858\n",
      "330 0.030554696917533875\n",
      "331 0.029385512694716454\n",
      "332 0.02826041169464588\n",
      "333 0.027201997116208076\n",
      "334 0.026143576949834824\n",
      "335 0.02515074796974659\n",
      "336 0.02416982129216194\n",
      "337 0.023249484598636627\n",
      "338 0.022340822964906693\n",
      "339 0.021497495472431183\n",
      "340 0.02067314274609089\n",
      "341 0.019893934950232506\n",
      "342 0.019135084003210068\n",
      "343 0.018409647047519684\n",
      "344 0.01770138368010521\n",
      "345 0.017027560621500015\n",
      "346 0.01637778803706169\n",
      "347 0.015751995146274567\n",
      "348 0.015169273130595684\n",
      "349 0.014594734646379948\n",
      "350 0.014042062684893608\n",
      "351 0.013518067076802254\n",
      "352 0.012995004653930664\n",
      "353 0.01251642219722271\n",
      "354 0.012037063017487526\n",
      "355 0.01158798299729824\n",
      "356 0.01116067636758089\n",
      "357 0.010737095959484577\n",
      "358 0.010327454656362534\n",
      "359 0.009948747232556343\n",
      "360 0.009584382176399231\n",
      "361 0.009212834760546684\n",
      "362 0.008881017565727234\n",
      "363 0.008554313331842422\n",
      "364 0.008241744711995125\n",
      "365 0.007934057153761387\n",
      "366 0.007638837676495314\n",
      "367 0.007357418537139893\n",
      "368 0.007082456257194281\n",
      "369 0.006828388664871454\n",
      "370 0.006581165827810764\n",
      "371 0.006339694373309612\n",
      "372 0.0061059133149683475\n",
      "373 0.0058866990730166435\n",
      "374 0.005680044647306204\n",
      "375 0.00547185679897666\n",
      "376 0.005273601971566677\n",
      "377 0.005086683202534914\n",
      "378 0.004901489242911339\n",
      "379 0.004729813896119595\n",
      "380 0.004559357650578022\n",
      "381 0.004396879579871893\n",
      "382 0.004242406692355871\n",
      "383 0.004087431356310844\n",
      "384 0.003945330623537302\n",
      "385 0.0038087856955826283\n",
      "386 0.0036758016794919968\n",
      "387 0.00354508007876575\n",
      "388 0.0034215031191706657\n",
      "389 0.0033003012649714947\n",
      "390 0.0031862352043390274\n",
      "391 0.003076043911278248\n",
      "392 0.002965626074001193\n",
      "393 0.0028709217440336943\n",
      "394 0.002775231609120965\n",
      "395 0.002676728181540966\n",
      "396 0.002586224116384983\n",
      "397 0.002499134512618184\n",
      "398 0.002418592106550932\n",
      "399 0.002337113255634904\n",
      "400 0.002260513138025999\n",
      "401 0.0021844024304300547\n",
      "402 0.0021157972514629364\n",
      "403 0.002045978792011738\n",
      "404 0.00197627954185009\n",
      "405 0.0019138745265081525\n",
      "406 0.0018534761620685458\n",
      "407 0.0017919924575835466\n",
      "408 0.001736607402563095\n",
      "409 0.0016797343268990517\n",
      "410 0.0016277917893603444\n",
      "411 0.0015759619418531656\n",
      "412 0.0015239885542541742\n",
      "413 0.001478802994824946\n",
      "414 0.0014344813534989953\n",
      "415 0.0013870183611288667\n",
      "416 0.00134684715885669\n",
      "417 0.001305203652009368\n",
      "418 0.0012663432862609625\n",
      "419 0.0012273851316422224\n",
      "420 0.001191479037515819\n",
      "421 0.0011566956527531147\n",
      "422 0.0011240208987146616\n",
      "423 0.0010904667433351278\n",
      "424 0.0010565073462203145\n",
      "425 0.0010266646277159452\n",
      "426 0.0009980694158002734\n",
      "427 0.0009693430038169026\n",
      "428 0.0009412409854121506\n",
      "429 0.0009155220468528569\n",
      "430 0.0008890503668226302\n",
      "431 0.0008642191532999277\n",
      "432 0.0008391804876737297\n",
      "433 0.0008158748969435692\n",
      "434 0.0007935847388580441\n",
      "435 0.0007729940116405487\n",
      "436 0.0007539525395259261\n",
      "437 0.0007341143791563809\n",
      "438 0.0007160130189731717\n",
      "439 0.0006963270134292543\n",
      "440 0.0006769311730749905\n",
      "441 0.0006596245802938938\n",
      "442 0.0006415460957214236\n",
      "443 0.0006239285576157272\n",
      "444 0.0006104109925217927\n",
      "445 0.0005934128421358764\n",
      "446 0.000579279032535851\n",
      "447 0.0005646905046887696\n",
      "448 0.0005509050679393113\n",
      "449 0.0005382061935961246\n",
      "450 0.0005245598731562495\n",
      "451 0.0005124557064846158\n",
      "452 0.0005000762175768614\n",
      "453 0.0004888066905550659\n",
      "454 0.0004774400149472058\n",
      "455 0.00046503200428560376\n",
      "456 0.0004547197313513607\n",
      "457 0.000443092460045591\n",
      "458 0.00043363828444853425\n",
      "459 0.00042311963625252247\n",
      "460 0.0004135289345867932\n",
      "461 0.00040386756882071495\n",
      "462 0.0003948469238821417\n",
      "463 0.00038579042302444577\n",
      "464 0.0003775199002120644\n",
      "465 0.00036896675010211766\n",
      "466 0.0003608510014601052\n",
      "467 0.00035356602165848017\n",
      "468 0.0003456435806583613\n",
      "469 0.0003386794123798609\n",
      "470 0.0003307842998765409\n",
      "471 0.0003235717595089227\n",
      "472 0.0003166652168147266\n",
      "473 0.0003096241853199899\n",
      "474 0.0003030151128768921\n",
      "475 0.0002968981862068176\n",
      "476 0.0002910361799877137\n",
      "477 0.0002852199540939182\n",
      "478 0.0002797211636789143\n",
      "479 0.00027393028722144663\n",
      "480 0.0002686203515622765\n",
      "481 0.0002645183994900435\n",
      "482 0.00025845132768154144\n",
      "483 0.0002541100257076323\n",
      "484 0.00024828381719999015\n",
      "485 0.00024328494328074157\n",
      "486 0.00023878755746409297\n",
      "487 0.00023390803835354745\n",
      "488 0.00022880459437146783\n",
      "489 0.00022481042833533138\n",
      "490 0.00022144328977447003\n",
      "491 0.00021678453776985407\n",
      "492 0.00021265033865347505\n",
      "493 0.00020832722657360137\n",
      "494 0.00020505614520516247\n",
      "495 0.00020162416331004351\n",
      "496 0.00019800601876340806\n",
      "497 0.0001937933557201177\n",
      "498 0.00019035469449590892\n",
      "499 0.0001872063148766756\n"
     ]
    }
   ],
   "source": [
    "# Code in file tensor/two_layer_net_tensor.py\n",
    "import torch\n",
    "\n",
    "#dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.randn(N, D_in).type(dtype)\n",
    "y = torch.randn(N, D_out).type(dtype)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = torch.randn(D_in, H).type(dtype)\n",
    "w2 = torch.randn(H, D_out).type(dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "  \n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss)\n",
    "  \n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "  \n",
    "    # Update weights using gradient descent\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: Variables and autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 22377096.0\n",
      "1 19034090.0\n",
      "2 19379214.0\n",
      "3 21014446.0\n",
      "4 21881262.0\n",
      "5 20300738.0\n",
      "6 16203696.0\n",
      "7 11085920.0\n",
      "8 6760728.5\n",
      "9 3891078.0\n",
      "10 2254802.5\n",
      "11 1381930.875\n",
      "12 920535.375\n",
      "13 667264.8125\n",
      "14 518036.8125\n",
      "15 422081.34375\n",
      "16 354813.375\n",
      "17 304161.0625\n",
      "18 263985.71875\n",
      "19 230973.46875\n",
      "20 203265.65625\n",
      "21 179709.78125\n",
      "22 159457.96875\n",
      "23 141940.078125\n",
      "24 126692.140625\n",
      "25 113382.9140625\n",
      "26 101712.75\n",
      "27 91449.0859375\n",
      "28 82393.640625\n",
      "29 74379.59375\n",
      "30 67267.5703125\n",
      "31 60943.046875\n",
      "32 55307.73046875\n",
      "33 50281.6015625\n",
      "34 45787.12890625\n",
      "35 41755.6171875\n",
      "36 38135.63671875\n",
      "37 34878.83203125\n",
      "38 31941.423828125\n",
      "39 29290.90625\n",
      "40 26892.0859375\n",
      "41 24719.134765625\n",
      "42 22745.91015625\n",
      "43 20953.205078125\n",
      "44 19321.705078125\n",
      "45 17836.287109375\n",
      "46 16481.330078125\n",
      "47 15243.416015625\n",
      "48 14111.955078125\n",
      "49 13076.30078125\n",
      "50 12127.0126953125\n",
      "51 11255.9755859375\n",
      "52 10455.509765625\n",
      "53 9719.4482421875\n",
      "54 9042.8232421875\n",
      "55 8421.591796875\n",
      "56 7848.515625\n",
      "57 7319.64990234375\n",
      "58 6830.8720703125\n",
      "59 6379.00146484375\n",
      "60 5960.50439453125\n",
      "61 5572.41552734375\n",
      "62 5212.564453125\n",
      "63 4878.599609375\n",
      "64 4568.35009765625\n",
      "65 4280.32568359375\n",
      "66 4012.776123046875\n",
      "67 3763.565673828125\n",
      "68 3531.343505859375\n",
      "69 3314.90966796875\n",
      "70 3112.999755859375\n",
      "71 2924.738037109375\n",
      "72 2748.80078125\n",
      "73 2584.59814453125\n",
      "74 2431.035888671875\n",
      "75 2287.41162109375\n",
      "76 2152.90869140625\n",
      "77 2026.9532470703125\n",
      "78 1908.9854736328125\n",
      "79 1798.4278564453125\n",
      "80 1694.813232421875\n",
      "81 1597.5809326171875\n",
      "82 1506.29443359375\n",
      "83 1420.6217041015625\n",
      "84 1340.130615234375\n",
      "85 1264.5601806640625\n",
      "86 1193.5225830078125\n",
      "87 1126.6973876953125\n",
      "88 1063.8477783203125\n",
      "89 1004.7669677734375\n",
      "90 949.1119995117188\n",
      "91 896.7474975585938\n",
      "92 847.41845703125\n",
      "93 800.9869995117188\n",
      "94 757.2017211914062\n",
      "95 715.9552001953125\n",
      "96 677.0638427734375\n",
      "97 640.4132690429688\n",
      "98 605.846923828125\n",
      "99 573.2061767578125\n",
      "100 542.4083862304688\n",
      "101 513.3272705078125\n",
      "102 485.88458251953125\n",
      "103 459.9708251953125\n",
      "104 435.4869384765625\n",
      "105 412.3655090332031\n",
      "106 390.52264404296875\n",
      "107 369.88616943359375\n",
      "108 350.40472412109375\n",
      "109 331.98419189453125\n",
      "110 314.5510559082031\n",
      "111 298.0574645996094\n",
      "112 282.4572448730469\n",
      "113 267.70556640625\n",
      "114 253.74298095703125\n",
      "115 240.5367431640625\n",
      "116 228.0423126220703\n",
      "117 216.20858764648438\n",
      "118 205.02366638183594\n",
      "119 194.4236602783203\n",
      "120 184.3892364501953\n",
      "121 174.879150390625\n",
      "122 165.87725830078125\n",
      "123 157.34963989257812\n",
      "124 149.27447509765625\n",
      "125 141.6172637939453\n",
      "126 134.36720275878906\n",
      "127 127.49629211425781\n",
      "128 120.98515319824219\n",
      "129 114.82221221923828\n",
      "130 108.97415924072266\n",
      "131 103.43061065673828\n",
      "132 98.17345428466797\n",
      "133 93.18386840820312\n",
      "134 88.45512390136719\n",
      "135 83.97029876708984\n",
      "136 79.71890258789062\n",
      "137 75.68875122070312\n",
      "138 71.86320495605469\n",
      "139 68.23421478271484\n",
      "140 64.79461669921875\n",
      "141 61.531288146972656\n",
      "142 58.43408203125\n",
      "143 55.49718475341797\n",
      "144 52.70870590209961\n",
      "145 50.062522888183594\n",
      "146 47.55069351196289\n",
      "147 45.16709518432617\n",
      "148 42.907081604003906\n",
      "149 40.75966262817383\n",
      "150 38.72340774536133\n",
      "151 36.788448333740234\n",
      "152 34.95181655883789\n",
      "153 33.20965576171875\n",
      "154 31.5559139251709\n",
      "155 29.98450469970703\n",
      "156 28.492589950561523\n",
      "157 27.076684951782227\n",
      "158 25.73012351989746\n",
      "159 24.452510833740234\n",
      "160 23.23926544189453\n",
      "161 22.086458206176758\n",
      "162 20.99154281616211\n",
      "163 19.951826095581055\n",
      "164 18.96428108215332\n",
      "165 18.027421951293945\n",
      "166 17.13669204711914\n",
      "167 16.2896728515625\n",
      "168 15.48561954498291\n",
      "169 14.721780776977539\n",
      "170 13.995455741882324\n",
      "171 13.30576229095459\n",
      "172 12.650193214416504\n",
      "173 12.02734661102295\n",
      "174 11.435392379760742\n",
      "175 10.872740745544434\n",
      "176 10.33843994140625\n",
      "177 9.830666542053223\n",
      "178 9.348311424255371\n",
      "179 8.889676094055176\n",
      "180 8.453727722167969\n",
      "181 8.038924217224121\n",
      "182 7.644736289978027\n",
      "183 7.270111560821533\n",
      "184 6.91400146484375\n",
      "185 6.575626850128174\n",
      "186 6.254117012023926\n",
      "187 5.948294162750244\n",
      "188 5.657561779022217\n",
      "189 5.381317615509033\n",
      "190 5.118453502655029\n",
      "191 4.868612289428711\n",
      "192 4.630998134613037\n",
      "193 4.405183792114258\n",
      "194 4.190517425537109\n",
      "195 3.9861502647399902\n",
      "196 3.7921485900878906\n",
      "197 3.6074907779693604\n",
      "198 3.4316728115081787\n",
      "199 3.264801263809204\n",
      "200 3.105867862701416\n",
      "201 2.9549241065979004\n",
      "202 2.811197280883789\n",
      "203 2.67475962638855\n",
      "204 2.5446829795837402\n",
      "205 2.421159267425537\n",
      "206 2.3036365509033203\n",
      "207 2.191948175430298\n",
      "208 2.085679769515991\n",
      "209 1.9844446182250977\n",
      "210 1.8883763551712036\n",
      "211 1.796711802482605\n",
      "212 1.7097644805908203\n",
      "213 1.6268671751022339\n",
      "214 1.548134446144104\n",
      "215 1.47333562374115\n",
      "216 1.4020066261291504\n",
      "217 1.3341912031173706\n",
      "218 1.269683599472046\n",
      "219 1.2082966566085815\n",
      "220 1.1499168872833252\n",
      "221 1.094282627105713\n",
      "222 1.0413777828216553\n",
      "223 0.9910888075828552\n",
      "224 0.9432969689369202\n",
      "225 0.8977951407432556\n",
      "226 0.8545507192611694\n",
      "227 0.8133531212806702\n",
      "228 0.7739993929862976\n",
      "229 0.7367101907730103\n",
      "230 0.7011821269989014\n",
      "231 0.6673948168754578\n",
      "232 0.6352099776268005\n",
      "233 0.6047050356864929\n",
      "234 0.5755455493927002\n",
      "235 0.5478481650352478\n",
      "236 0.5215226411819458\n",
      "237 0.4965294897556305\n",
      "238 0.4725323021411896\n",
      "239 0.44985121488571167\n",
      "240 0.42823630571365356\n",
      "241 0.4076090455055237\n",
      "242 0.3880535960197449\n",
      "243 0.3693365156650543\n",
      "244 0.35157403349876404\n",
      "245 0.334755003452301\n",
      "246 0.31867045164108276\n",
      "247 0.3034173548221588\n",
      "248 0.2888585329055786\n",
      "249 0.27500009536743164\n",
      "250 0.2617867887020111\n",
      "251 0.2492186576128006\n",
      "252 0.23729439079761505\n",
      "253 0.22585663199424744\n",
      "254 0.21510230004787445\n",
      "255 0.20478448271751404\n",
      "256 0.19497457146644592\n",
      "257 0.1856079250574112\n",
      "258 0.1767430454492569\n",
      "259 0.16826674342155457\n",
      "260 0.16018874943256378\n",
      "261 0.15256403386592865\n",
      "262 0.14524517953395844\n",
      "263 0.13825970888137817\n",
      "264 0.13168483972549438\n",
      "265 0.12538886070251465\n",
      "266 0.11939334869384766\n",
      "267 0.11371424794197083\n",
      "268 0.10826307535171509\n",
      "269 0.10309486836194992\n",
      "270 0.09815945476293564\n",
      "271 0.09347281605005264\n",
      "272 0.08901187032461166\n",
      "273 0.08474444597959518\n",
      "274 0.080724336206913\n",
      "275 0.07686464488506317\n",
      "276 0.07319918274879456\n",
      "277 0.06970973312854767\n",
      "278 0.06638657301664352\n",
      "279 0.06322375684976578\n",
      "280 0.06020912155508995\n",
      "281 0.057346127927303314\n",
      "282 0.05459784343838692\n",
      "283 0.0520322322845459\n",
      "284 0.04953913018107414\n",
      "285 0.04716864973306656\n",
      "286 0.04492325335741043\n",
      "287 0.04278934374451637\n",
      "288 0.04075653478503227\n",
      "289 0.03880588710308075\n",
      "290 0.03697781637310982\n",
      "291 0.03522941842675209\n",
      "292 0.03355163708329201\n",
      "293 0.0319565087556839\n",
      "294 0.030436577275395393\n",
      "295 0.028998157009482384\n",
      "296 0.02761838026344776\n",
      "297 0.026321299374103546\n",
      "298 0.02507116086781025\n",
      "299 0.02390040084719658\n",
      "300 0.022760191932320595\n",
      "301 0.02170339971780777\n",
      "302 0.020686734467744827\n",
      "303 0.019708195701241493\n",
      "304 0.018776068463921547\n",
      "305 0.01787940226495266\n",
      "306 0.017040900886058807\n",
      "307 0.016247685998678207\n",
      "308 0.015489117242395878\n",
      "309 0.014766287058591843\n",
      "310 0.014068441465497017\n",
      "311 0.013417830690741539\n",
      "312 0.012787123210728168\n",
      "313 0.012199753895401955\n",
      "314 0.011632204055786133\n",
      "315 0.0110833290964365\n",
      "316 0.010573851875960827\n",
      "317 0.010079720057547092\n",
      "318 0.009619351476430893\n",
      "319 0.009168910793960094\n",
      "320 0.008751669898629189\n",
      "321 0.00834251381456852\n",
      "322 0.007962197996675968\n",
      "323 0.007597970310598612\n",
      "324 0.0072518992237746716\n",
      "325 0.006921518128365278\n",
      "326 0.006609047297388315\n",
      "327 0.00630686292424798\n",
      "328 0.00602760212495923\n",
      "329 0.005750248208642006\n",
      "330 0.005492334254086018\n",
      "331 0.005241728387773037\n",
      "332 0.00500834733247757\n",
      "333 0.00478714145720005\n",
      "334 0.004570867866277695\n",
      "335 0.004370268899947405\n",
      "336 0.004182858392596245\n",
      "337 0.003997461870312691\n",
      "338 0.003823273116722703\n",
      "339 0.003655913984403014\n",
      "340 0.0035001086071133614\n",
      "341 0.0033451367635279894\n",
      "342 0.0032029321882873774\n",
      "343 0.0030651078559458256\n",
      "344 0.0029365757945924997\n",
      "345 0.002812677063047886\n",
      "346 0.0026929895393550396\n",
      "347 0.002579928608611226\n",
      "348 0.0024722570087760687\n",
      "349 0.0023686301428824663\n",
      "350 0.002268671989440918\n",
      "351 0.0021770079620182514\n",
      "352 0.00208593113347888\n",
      "353 0.0020019456278532743\n",
      "354 0.0019208132289350033\n",
      "355 0.0018427169416099787\n",
      "356 0.0017718062736093998\n",
      "357 0.0017019587103277445\n",
      "358 0.0016338208224624395\n",
      "359 0.0015681457007303834\n",
      "360 0.0015068441862240434\n",
      "361 0.0014479240635409951\n",
      "362 0.0013936422765254974\n",
      "363 0.0013382809702306986\n",
      "364 0.0012883655726909637\n",
      "365 0.0012391542550176382\n",
      "366 0.0011963453143835068\n",
      "367 0.001149912946857512\n",
      "368 0.001107047195546329\n",
      "369 0.0010659120744094253\n",
      "370 0.0010300383437424898\n",
      "371 0.0009900478180497885\n",
      "372 0.0009552459814585745\n",
      "373 0.0009213557350449264\n",
      "374 0.0008873448241502047\n",
      "375 0.0008564502350054681\n",
      "376 0.0008286323864012957\n",
      "377 0.000798171735368669\n",
      "378 0.0007716810214333236\n",
      "379 0.0007443943177349865\n",
      "380 0.0007188412710092962\n",
      "381 0.0006949846283532679\n",
      "382 0.0006739993114024401\n",
      "383 0.0006509398226626217\n",
      "384 0.0006290922174230218\n",
      "385 0.0006091796094551682\n",
      "386 0.000590160780120641\n",
      "387 0.0005714666331186891\n",
      "388 0.0005533620715141296\n",
      "389 0.0005348795675672591\n",
      "390 0.0005197548889555037\n",
      "391 0.0005033943452872336\n",
      "392 0.00048703886568546295\n",
      "393 0.0004723826714325696\n",
      "394 0.00045793390017934144\n",
      "395 0.00044436182361096144\n",
      "396 0.00043127776007167995\n",
      "397 0.0004183316486887634\n",
      "398 0.0004054174933116883\n",
      "399 0.0003940069873351604\n",
      "400 0.0003819426638074219\n",
      "401 0.00037194413016550243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402 0.0003615499008446932\n",
      "403 0.00035100162494927645\n",
      "404 0.00034203394898213446\n",
      "405 0.0003327681333757937\n",
      "406 0.00032392231514677405\n",
      "407 0.00031438632868230343\n",
      "408 0.0003065534110646695\n",
      "409 0.00029807418468408287\n",
      "410 0.0002904129505623132\n",
      "411 0.0002825179835781455\n",
      "412 0.0002752671716734767\n",
      "413 0.0002676322765182704\n",
      "414 0.0002607099886517972\n",
      "415 0.0002536948013585061\n",
      "416 0.00024679023772478104\n",
      "417 0.0002403460821369663\n",
      "418 0.00023492882610298693\n",
      "419 0.00022852406254969537\n",
      "420 0.000222338130697608\n",
      "421 0.0002176494017476216\n",
      "422 0.00021311633463483304\n",
      "423 0.00020772573770955205\n",
      "424 0.00020254182163625956\n",
      "425 0.00019794123363681138\n",
      "426 0.0001932195882545784\n",
      "427 0.0001887372782221064\n",
      "428 0.00018430115596856922\n",
      "429 0.00017973802459891886\n",
      "430 0.00017556057719048113\n",
      "431 0.00017122150165960193\n",
      "432 0.0001682949368841946\n",
      "433 0.00016469851834699512\n",
      "434 0.00016121334920171648\n",
      "435 0.00015747279394418\n",
      "436 0.00015372165944427252\n",
      "437 0.0001503937237430364\n",
      "438 0.00014740013284608722\n",
      "439 0.00014395250764209777\n",
      "440 0.00014098832616582513\n",
      "441 0.0001379245222778991\n",
      "442 0.00013530389696825296\n",
      "443 0.00013246751041151583\n",
      "444 0.000129722073324956\n",
      "445 0.0001272297085961327\n",
      "446 0.00012456004333216697\n",
      "447 0.00012201294157421216\n",
      "448 0.00011976876703556627\n",
      "449 0.00011762625945266336\n",
      "450 0.00011552602518349886\n",
      "451 0.00011276704753981903\n",
      "452 0.00011055465438403189\n",
      "453 0.00010873217979678884\n",
      "454 0.00010650094191078097\n",
      "455 0.00010479077900527045\n",
      "456 0.00010245449811918661\n",
      "457 0.0001007423852570355\n",
      "458 9.900028089759871e-05\n",
      "459 9.718742512632161e-05\n",
      "460 9.592923743184656e-05\n",
      "461 9.392673382535577e-05\n",
      "462 9.181139466818422e-05\n",
      "463 9.021307778311893e-05\n",
      "464 8.886301657184958e-05\n",
      "465 8.722541679162532e-05\n",
      "466 8.581825386499986e-05\n",
      "467 8.40698485262692e-05\n",
      "468 8.284230716526508e-05\n",
      "469 8.145238098222762e-05\n",
      "470 8.002371032489464e-05\n",
      "471 7.865804218454286e-05\n",
      "472 7.706491305725649e-05\n",
      "473 7.605553400935605e-05\n",
      "474 7.481475768145174e-05\n",
      "475 7.39005408831872e-05\n",
      "476 7.23648990970105e-05\n",
      "477 7.120701775420457e-05\n",
      "478 6.987471715547144e-05\n",
      "479 6.943126936675981e-05\n",
      "480 6.82916070218198e-05\n",
      "481 6.712761387461796e-05\n",
      "482 6.615937309106812e-05\n",
      "483 6.519492308143526e-05\n",
      "484 6.381249113474041e-05\n",
      "485 6.290058809099719e-05\n",
      "486 6.172579014673829e-05\n",
      "487 6.0846577980555594e-05\n",
      "488 6.023007881594822e-05\n",
      "489 5.9124799008714035e-05\n",
      "490 5.8125719078816473e-05\n",
      "491 5.7698947784956545e-05\n",
      "492 5.6723107263678685e-05\n",
      "493 5.6274420785484836e-05\n",
      "494 5.523217623704113e-05\n",
      "495 5.473953206092119e-05\n",
      "496 5.3785366617375985e-05\n",
      "497 5.2876610425300896e-05\n",
      "498 5.225318091106601e-05\n",
      "499 5.174187390366569e-05\n"
     ]
    }
   ],
   "source": [
    "# Code in file autograd/two_layer_net_autograd.py\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs, and wrap them in Variables.\n",
    "# Setting requires_grad=False indicates that we do not need to compute gradients\n",
    "# with respect to these Variables during the backward pass.\n",
    "x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False)\n",
    "y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n",
    "\n",
    "# Create random Tensors for weights, and wrap them in Variables.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Variables during the backward pass.\n",
    "w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)\n",
    "w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y using operations on Variables; these\n",
    "    # are exactly the same operations we used to compute the forward pass using\n",
    "    # Tensors, but we do not need to keep references to intermediate values since\n",
    "    # we are not implementing the backward pass by hand.\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    \n",
    "    # Compute and print loss using operations on Variables.\n",
    "    # Now loss is a Variable of shape (1,) and loss.data is a Tensor of shape\n",
    "    # (1,); loss.data[0] is a scalar value holding the loss.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.data[0])\n",
    "    \n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this call w1.grad and w2.grad will be Variables holding the gradient\n",
    "    # of the loss with respect to w1 and w2 respectively.\n",
    "    loss.backward()\n",
    "\n",
    "\n",
    "    # Update weights using gradient descent; w1.data and w2.data are Tensors,\n",
    "    # w1.grad and w2.grad are Variables and w1.grad.data and w2.grad.data are\n",
    "    # Tensors.\n",
    "    w1.data -= learning_rate * w1.grad.data\n",
    "    w2.data -= learning_rate * w2.grad.data\n",
    "    \n",
    "    # Manually zero the gradients before running the backward pass\n",
    "    #w1.grad.data.zero_()\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: Defining new autograd functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 32114520.0\n",
      "1 27009834.0\n",
      "2 23622512.0\n",
      "3 19190498.0\n",
      "4 14071144.0\n",
      "5 9331276.0\n",
      "6 5879006.0\n",
      "7 3684305.0\n",
      "8 2401114.5\n",
      "9 1658749.5\n",
      "10 1218721.0\n",
      "11 942771.0\n",
      "12 758475.0625\n",
      "13 626876.3125\n",
      "14 527602.0\n",
      "15 449697.375\n",
      "16 386727.375\n",
      "17 334730.5\n",
      "18 291242.125\n",
      "19 254544.3125\n",
      "20 223325.328125\n",
      "21 196590.40625\n",
      "22 173573.671875\n",
      "23 153678.4375\n",
      "24 136428.03125\n",
      "25 121421.109375\n",
      "26 108320.34375\n",
      "27 96869.7734375\n",
      "28 86825.9140625\n",
      "29 77982.4375\n",
      "30 70176.9140625\n",
      "31 63267.24609375\n",
      "32 57135.34375\n",
      "33 51684.0390625\n",
      "34 46829.01171875\n",
      "35 42495.40234375\n",
      "36 38621.4609375\n",
      "37 35153.2421875\n",
      "38 32041.98828125\n",
      "39 29248.029296875\n",
      "40 26734.92578125\n",
      "41 24470.96484375\n",
      "42 22426.390625\n",
      "43 20578.470703125\n",
      "44 18905.396484375\n",
      "45 17389.16015625\n",
      "46 16013.572265625\n",
      "47 14762.6044921875\n",
      "48 13624.7880859375\n",
      "49 12588.0810546875\n",
      "50 11642.0341796875\n",
      "51 10778.1875\n",
      "52 9987.966796875\n",
      "53 9264.6923828125\n",
      "54 8601.900390625\n",
      "55 7993.92578125\n",
      "56 7435.7705078125\n",
      "57 6922.689453125\n",
      "58 6450.3603515625\n",
      "59 6015.4453125\n",
      "60 5614.20458984375\n",
      "61 5243.9296875\n",
      "62 4901.658203125\n",
      "63 4585.017578125\n",
      "64 4291.87548828125\n",
      "65 4020.228759765625\n",
      "66 3768.24951171875\n",
      "67 3534.386474609375\n",
      "68 3317.182373046875\n",
      "69 3115.3193359375\n",
      "70 2927.346435546875\n",
      "71 2752.28955078125\n",
      "72 2589.1318359375\n",
      "73 2436.97216796875\n",
      "74 2294.958251953125\n",
      "75 2162.315673828125\n",
      "76 2038.3779296875\n",
      "77 1922.4140625\n",
      "78 1813.870849609375\n",
      "79 1712.18994140625\n",
      "80 1616.9906005859375\n",
      "81 1527.727783203125\n",
      "82 1443.976318359375\n",
      "83 1365.3284912109375\n",
      "84 1291.468505859375\n",
      "85 1222.04833984375\n",
      "86 1156.807373046875\n",
      "87 1095.455078125\n",
      "88 1037.6915283203125\n",
      "89 983.3098754882812\n",
      "90 932.0653076171875\n",
      "91 883.7426147460938\n",
      "92 838.1813354492188\n",
      "93 795.192626953125\n",
      "94 754.6039428710938\n",
      "95 716.2827758789062\n",
      "96 680.0762329101562\n",
      "97 645.857177734375\n",
      "98 613.508544921875\n",
      "99 582.9214477539062\n",
      "100 553.9849243164062\n",
      "101 526.60595703125\n",
      "102 500.66912841796875\n",
      "103 476.1195373535156\n",
      "104 452.8547058105469\n",
      "105 430.811767578125\n",
      "106 409.9220275878906\n",
      "107 390.10809326171875\n",
      "108 371.3253479003906\n",
      "109 353.5107421875\n",
      "110 336.5996398925781\n",
      "111 320.54852294921875\n",
      "112 305.3158264160156\n",
      "113 290.8440246582031\n",
      "114 277.1063537597656\n",
      "115 264.0555114746094\n",
      "116 251.6507110595703\n",
      "117 239.86741638183594\n",
      "118 228.66415405273438\n",
      "119 218.00698852539062\n",
      "120 207.8761444091797\n",
      "121 198.2399139404297\n",
      "122 189.07879638671875\n",
      "123 180.35630798339844\n",
      "124 172.05836486816406\n",
      "125 164.1571807861328\n",
      "126 156.6431884765625\n",
      "127 149.48492431640625\n",
      "128 142.66612243652344\n",
      "129 136.1930389404297\n",
      "130 130.02980041503906\n",
      "131 124.1578140258789\n",
      "132 118.56421661376953\n",
      "133 113.23268127441406\n",
      "134 108.15242767333984\n",
      "135 103.310791015625\n",
      "136 98.69596862792969\n",
      "137 94.2918701171875\n",
      "138 90.09606170654297\n",
      "139 86.09143829345703\n",
      "140 82.27239990234375\n",
      "141 78.6290054321289\n",
      "142 75.15451049804688\n",
      "143 71.83924865722656\n",
      "144 68.6781005859375\n",
      "145 65.65838623046875\n",
      "146 62.77751541137695\n",
      "147 60.02809524536133\n",
      "148 57.40003967285156\n",
      "149 54.89447021484375\n",
      "150 52.498931884765625\n",
      "151 50.21189498901367\n",
      "152 48.03056335449219\n",
      "153 45.94610595703125\n",
      "154 43.95402908325195\n",
      "155 42.05113983154297\n",
      "156 40.23484420776367\n",
      "157 38.49882125854492\n",
      "158 36.83974075317383\n",
      "159 35.253822326660156\n",
      "160 33.738983154296875\n",
      "161 32.2906494140625\n",
      "162 30.907249450683594\n",
      "163 29.583675384521484\n",
      "164 28.32010841369629\n",
      "165 27.11138916015625\n",
      "166 25.956037521362305\n",
      "167 24.850521087646484\n",
      "168 23.794160842895508\n",
      "169 22.782695770263672\n",
      "170 21.8173828125\n",
      "171 20.892797470092773\n",
      "172 20.00873374938965\n",
      "173 19.163135528564453\n",
      "174 18.354459762573242\n",
      "175 17.58100128173828\n",
      "176 16.840709686279297\n",
      "177 16.132795333862305\n",
      "178 15.454254150390625\n",
      "179 14.806680679321289\n",
      "180 14.185791015625\n",
      "181 13.592554092407227\n",
      "182 13.024035453796387\n",
      "183 12.480002403259277\n",
      "184 11.958516120910645\n",
      "185 11.459983825683594\n",
      "186 10.98360538482666\n",
      "187 10.525575637817383\n",
      "188 10.08931827545166\n",
      "189 9.670698165893555\n",
      "190 9.26974868774414\n",
      "191 8.886126518249512\n",
      "192 8.518329620361328\n",
      "193 8.166354179382324\n",
      "194 7.828657627105713\n",
      "195 7.505843639373779\n",
      "196 7.196954250335693\n",
      "197 6.900550842285156\n",
      "198 6.616805553436279\n",
      "199 6.344537734985352\n",
      "200 6.084155082702637\n",
      "201 5.834694862365723\n",
      "202 5.595579624176025\n",
      "203 5.366833209991455\n",
      "204 5.147291660308838\n",
      "205 4.936931610107422\n",
      "206 4.735388278961182\n",
      "207 4.542361736297607\n",
      "208 4.357168197631836\n",
      "209 4.180078029632568\n",
      "210 4.009642124176025\n",
      "211 3.8466641902923584\n",
      "212 3.6902852058410645\n",
      "213 3.5407071113586426\n",
      "214 3.3974766731262207\n",
      "215 3.259833335876465\n",
      "216 3.1278538703918457\n",
      "217 3.001270055770874\n",
      "218 2.8801701068878174\n",
      "219 2.763873338699341\n",
      "220 2.6526567935943604\n",
      "221 2.545661211013794\n",
      "222 2.443138837814331\n",
      "223 2.344893217086792\n",
      "224 2.250704526901245\n",
      "225 2.160250425338745\n",
      "226 2.073489189147949\n",
      "227 1.9903838634490967\n",
      "228 1.91057550907135\n",
      "229 1.8342183828353882\n",
      "230 1.7607693672180176\n",
      "231 1.6906371116638184\n",
      "232 1.622926115989685\n",
      "233 1.5582365989685059\n",
      "234 1.4962600469589233\n",
      "235 1.4366952180862427\n",
      "236 1.3795132637023926\n",
      "237 1.3245793581008911\n",
      "238 1.2719124555587769\n",
      "239 1.2214715480804443\n",
      "240 1.1729375123977661\n",
      "241 1.1263912916183472\n",
      "242 1.0819392204284668\n",
      "243 1.038886547088623\n",
      "244 0.9978649020195007\n",
      "245 0.9582756161689758\n",
      "246 0.9205461740493774\n",
      "247 0.8841389417648315\n",
      "248 0.8492299914360046\n",
      "249 0.8157806992530823\n",
      "250 0.7835258841514587\n",
      "251 0.7527769804000854\n",
      "252 0.723216712474823\n",
      "253 0.6946229338645935\n",
      "254 0.6673155426979065\n",
      "255 0.6412384510040283\n",
      "256 0.6160591244697571\n",
      "257 0.5919173359870911\n",
      "258 0.5686789751052856\n",
      "259 0.5464503765106201\n",
      "260 0.5251368284225464\n",
      "261 0.5045614838600159\n",
      "262 0.48475533723831177\n",
      "263 0.46590372920036316\n",
      "264 0.44773203134536743\n",
      "265 0.4302462637424469\n",
      "266 0.41349679231643677\n",
      "267 0.39745354652404785\n",
      "268 0.381972998380661\n",
      "269 0.36703142523765564\n",
      "270 0.35282236337661743\n",
      "271 0.3390272259712219\n",
      "272 0.3258436322212219\n",
      "273 0.313167542219162\n",
      "274 0.30106568336486816\n",
      "275 0.28939589858055115\n",
      "276 0.2781621515750885\n",
      "277 0.26748740673065186\n",
      "278 0.25712019205093384\n",
      "279 0.2471732497215271\n",
      "280 0.23767051100730896\n",
      "281 0.2284848690032959\n",
      "282 0.21958787739276886\n",
      "283 0.21114985644817352\n",
      "284 0.20302820205688477\n",
      "285 0.1951737105846405\n",
      "286 0.18766097724437714\n",
      "287 0.18045911192893982\n",
      "288 0.17356117069721222\n",
      "289 0.16692356765270233\n",
      "290 0.16050085425376892\n",
      "291 0.15433171391487122\n",
      "292 0.1484127789735794\n",
      "293 0.14270810782909393\n",
      "294 0.1372145116329193\n",
      "295 0.13197511434555054\n",
      "296 0.12694722414016724\n",
      "297 0.12210328876972198\n",
      "298 0.11741968989372253\n",
      "299 0.11292717605829239\n",
      "300 0.10864529758691788\n",
      "301 0.10449086874723434\n",
      "302 0.10050121694803238\n",
      "303 0.09665821492671967\n",
      "304 0.09298330545425415\n",
      "305 0.08941321820020676\n",
      "306 0.08603061735630035\n",
      "307 0.08277548104524612\n",
      "308 0.07959242165088654\n",
      "309 0.07660257071256638\n",
      "310 0.07370195537805557\n",
      "311 0.0709109976887703\n",
      "312 0.06821763515472412\n",
      "313 0.06564334034919739\n",
      "314 0.06312976777553558\n",
      "315 0.060766495764255524\n",
      "316 0.05846930667757988\n",
      "317 0.056281909346580505\n",
      "318 0.05414782091975212\n",
      "319 0.052137814462184906\n",
      "320 0.05016090348362923\n",
      "321 0.04827852547168732\n",
      "322 0.04644326865673065\n",
      "323 0.044707104563713074\n",
      "324 0.043025366961956024\n",
      "325 0.0414259247481823\n",
      "326 0.03985702991485596\n",
      "327 0.03835517168045044\n",
      "328 0.03689505532383919\n",
      "329 0.03549607843160629\n",
      "330 0.0341794416308403\n",
      "331 0.03292512893676758\n",
      "332 0.03168724477291107\n",
      "333 0.030511466786265373\n",
      "334 0.029370656237006187\n",
      "335 0.028284717351198196\n",
      "336 0.02723238803446293\n",
      "337 0.02621697075664997\n",
      "338 0.025248536840081215\n",
      "339 0.024316327646374702\n",
      "340 0.023403432220220566\n",
      "341 0.022527555003762245\n",
      "342 0.021698590368032455\n",
      "343 0.02089884877204895\n",
      "344 0.02011682838201523\n",
      "345 0.019377481192350388\n",
      "346 0.01865570992231369\n",
      "347 0.01796761155128479\n",
      "348 0.017313361167907715\n",
      "349 0.016680410131812096\n",
      "350 0.01607007160782814\n",
      "351 0.015463598072528839\n",
      "352 0.014906641095876694\n",
      "353 0.014374667778611183\n",
      "354 0.013863896951079369\n",
      "355 0.013346661813557148\n",
      "356 0.012865707278251648\n",
      "357 0.012403866276144981\n",
      "358 0.01194816455245018\n",
      "359 0.011505215428769588\n",
      "360 0.011085626669228077\n",
      "361 0.010697027668356895\n",
      "362 0.010305533185601234\n",
      "363 0.009940670803189278\n",
      "364 0.009587174281477928\n",
      "365 0.009245594032108784\n",
      "366 0.008907929994165897\n",
      "367 0.008591931313276291\n",
      "368 0.008289660327136517\n",
      "369 0.007992222905158997\n",
      "370 0.007709479425102472\n",
      "371 0.007432786747813225\n",
      "372 0.007168235722929239\n",
      "373 0.0069125378504395485\n",
      "374 0.0066677723079919815\n",
      "375 0.006436833646148443\n",
      "376 0.006208733189851046\n",
      "377 0.005994588602334261\n",
      "378 0.005787039175629616\n",
      "379 0.005583831109106541\n",
      "380 0.005388597026467323\n",
      "381 0.005200255662202835\n",
      "382 0.005018611904233694\n",
      "383 0.0048463172279298306\n",
      "384 0.004681318067014217\n",
      "385 0.004518699832260609\n",
      "386 0.004363086074590683\n",
      "387 0.0042164744809269905\n",
      "388 0.004074854776263237\n",
      "389 0.003939188085496426\n",
      "390 0.0038069933652877808\n",
      "391 0.0036800841335207224\n",
      "392 0.003555619390681386\n",
      "393 0.0034353050868958235\n",
      "394 0.0033190599642693996\n",
      "395 0.003208952257409692\n",
      "396 0.0031034373678267\n",
      "397 0.002999756718054414\n",
      "398 0.002899591578170657\n",
      "399 0.002804324496537447\n",
      "400 0.0027151829563081264\n",
      "401 0.002627108246088028\n",
      "402 0.002540050772950053\n",
      "403 0.002459963783621788\n",
      "404 0.002380432328209281\n",
      "405 0.002303160959854722\n",
      "406 0.0022284535225480795\n",
      "407 0.0021582595072686672\n",
      "408 0.0020893074106425047\n",
      "409 0.002024145098403096\n",
      "410 0.0019616365898400545\n",
      "411 0.0019000237807631493\n",
      "412 0.0018426562892273068\n",
      "413 0.0017858020728453994\n",
      "414 0.0017313103890046477\n",
      "415 0.0016778182471171021\n",
      "416 0.0016272192588075995\n",
      "417 0.0015772090991958976\n",
      "418 0.0015314003685489297\n",
      "419 0.0014859025832265615\n",
      "420 0.0014409890864044428\n",
      "421 0.0013990681618452072\n",
      "422 0.0013563167303800583\n",
      "423 0.0013173904735594988\n",
      "424 0.0012814962537959218\n",
      "425 0.0012439116835594177\n",
      "426 0.0012114864075556397\n",
      "427 0.001174143049865961\n",
      "428 0.0011410594452172518\n",
      "429 0.0011094757355749607\n",
      "430 0.0010788411600515246\n",
      "431 0.001049574464559555\n",
      "432 0.0010193471098318696\n",
      "433 0.0009907105704769492\n",
      "434 0.0009629701962694526\n",
      "435 0.000937927863560617\n",
      "436 0.0009125554352067411\n",
      "437 0.0008881831308826804\n",
      "438 0.0008624056354165077\n",
      "439 0.0008379304781556129\n",
      "440 0.0008167870109900832\n",
      "441 0.0007952991873025894\n",
      "442 0.000774156185798347\n",
      "443 0.0007534429896622896\n",
      "444 0.0007352220709435642\n",
      "445 0.000715565518476069\n",
      "446 0.0006972626433707774\n",
      "447 0.0006820809212513268\n",
      "448 0.0006630486459471285\n",
      "449 0.0006469757063314319\n",
      "450 0.0006295092171058059\n",
      "451 0.0006148580578155816\n",
      "452 0.0005991622456349432\n",
      "453 0.0005841876263730228\n",
      "454 0.000569961208384484\n",
      "455 0.0005554183735512197\n",
      "456 0.0005429183365777135\n",
      "457 0.0005294411676004529\n",
      "458 0.0005163814639672637\n",
      "459 0.0005046711303293705\n",
      "460 0.0004927997360937297\n",
      "461 0.0004818360030185431\n",
      "462 0.0004709771310444921\n",
      "463 0.0004593146441038698\n",
      "464 0.0004491735599003732\n",
      "465 0.00043815368553623557\n",
      "466 0.0004279526765458286\n",
      "467 0.0004190246982034296\n",
      "468 0.00040917706792242825\n",
      "469 0.0004006529343314469\n",
      "470 0.0003911479434464127\n",
      "471 0.0003830500936601311\n",
      "472 0.00037429906660690904\n",
      "473 0.0003656776389107108\n",
      "474 0.00035796998417936265\n",
      "475 0.0003503106127027422\n",
      "476 0.00034268235322088003\n",
      "477 0.0003350688493810594\n",
      "478 0.00032868876587599516\n",
      "479 0.0003213238960597664\n",
      "480 0.00031480175675824285\n",
      "481 0.000308645743643865\n",
      "482 0.0003022535820491612\n",
      "483 0.00029646180337294936\n",
      "484 0.00029004260431975126\n",
      "485 0.00028420420130714774\n",
      "486 0.00027829495957121253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487 0.00027261607465334237\n",
      "488 0.0002675472933333367\n",
      "489 0.00026229163631796837\n",
      "490 0.00025686275330372155\n",
      "491 0.00025232823099941015\n",
      "492 0.0002469093888066709\n",
      "493 0.00024169577227439731\n",
      "494 0.00023723565391264856\n",
      "495 0.0002330009447177872\n",
      "496 0.00022851926041767\n",
      "497 0.0002238658635178581\n",
      "498 0.00021945075422991067\n",
      "499 0.00021549899247474968\n"
     ]
    }
   ],
   "source": [
    "# Code in file autograd/two_layer_net_custom_function.py\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class MyReLU(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return a\n",
    "        Tensor containing the output. You can cache arbitrary Tensors for use in the\n",
    "        backward pass using the save_for_backward method.\n",
    "        \"\"\"\n",
    "        self.save_for_backward(input)\n",
    "        return input.clamp(min=0)\n",
    "  \n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, = self.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input < 0] = 0\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "#dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs, and wrap them in Variables.\n",
    "x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False)\n",
    "y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n",
    "\n",
    "# Create random Tensors for weights, and wrap them in Variables.\n",
    "w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)\n",
    "w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Construct an instance of our MyReLU class to use in our network\n",
    "    relu = MyReLU()\n",
    "    \n",
    "    # Forward pass: compute predicted y using operations on Variables; we compute\n",
    "    # ReLU using our custom autograd operation.\n",
    "    y_pred = relu(x.mm(w1)).mm(w2)\n",
    "    \n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.data[0])\n",
    "  \n",
    "    # Use autograd to compute the backward pass.\n",
    "    loss.backward()\n",
    "  \n",
    "    # Update weights using gradient descent\n",
    "    w1.data -= learning_rate * w1.grad.data\n",
    "    w2.data -= learning_rate * w2.grad.data\n",
    "    \n",
    "    # Manually zero the gradients before running the backward pass\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow: Static Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1985e+07\n",
      "2.68149e+07\n",
      "2.83946e+07\n",
      "3.18445e+07\n",
      "3.25176e+07\n",
      "2.7697e+07\n",
      "1.87915e+07\n",
      "1.05402e+07\n",
      "5.37383e+06\n",
      "2.83132e+06\n",
      "1.67747e+06\n",
      "1.14142e+06\n",
      "864604.0\n",
      "699428.0\n",
      "586919.0\n",
      "502412.0\n",
      "435288.0\n",
      "380138.0\n",
      "333890.0\n",
      "294655.0\n",
      "261052.0\n",
      "232169.0\n",
      "207188.0\n",
      "185462.0\n",
      "166483.0\n",
      "149846.0\n",
      "135196.0\n",
      "122268.0\n",
      "110817.0\n",
      "100635.0\n",
      "91559.8\n",
      "83452.2\n",
      "76184.0\n",
      "69657.5\n",
      "63786.8\n",
      "58492.6\n",
      "53706.9\n",
      "49374.2\n",
      "45449.6\n",
      "41887.2\n",
      "38645.0\n",
      "35687.5\n",
      "32986.9\n",
      "30518.7\n",
      "28258.2\n",
      "26187.4\n",
      "24286.2\n",
      "22538.5\n",
      "20931.2\n",
      "19451.1\n",
      "18087.7\n",
      "16830.5\n",
      "15669.6\n",
      "14596.3\n",
      "13603.7\n",
      "12685.1\n",
      "11835.1\n",
      "11047.6\n",
      "10317.0\n",
      "9638.88\n",
      "9008.92\n",
      "8423.23\n",
      "7878.6\n",
      "7372.04\n",
      "6900.35\n",
      "6462.15\n",
      "6054.16\n",
      "5673.73\n",
      "5318.94\n",
      "4987.81\n",
      "4678.86\n",
      "4390.33\n",
      "4120.61\n",
      "3868.57\n",
      "3632.84\n",
      "3412.31\n",
      "3205.9\n",
      "3012.8\n",
      "2832.18\n",
      "2663.34\n",
      "2505.14\n",
      "2356.94\n",
      "2218.22\n",
      "2088.17\n",
      "1966.23\n",
      "1851.72\n",
      "1744.19\n",
      "1643.18\n",
      "1548.36\n",
      "1459.28\n",
      "1375.57\n",
      "1296.88\n",
      "1222.88\n",
      "1153.33\n",
      "1087.89\n",
      "1026.3\n",
      "968.35\n",
      "913.823\n",
      "862.51\n",
      "814.179\n",
      "768.645\n",
      "725.781\n",
      "685.388\n",
      "647.349\n",
      "611.484\n",
      "577.679\n",
      "545.812\n",
      "515.757\n",
      "487.406\n",
      "460.685\n",
      "435.468\n",
      "411.681\n",
      "389.228\n",
      "368.05\n",
      "348.068\n",
      "329.196\n",
      "311.38\n",
      "294.564\n",
      "278.677\n",
      "263.675\n",
      "249.508\n",
      "236.123\n",
      "223.472\n",
      "211.525\n",
      "200.233\n",
      "189.561\n",
      "179.478\n",
      "169.942\n",
      "160.929\n",
      "152.411\n",
      "144.349\n",
      "136.729\n",
      "129.517\n",
      "122.698\n",
      "116.247\n",
      "110.145\n",
      "104.373\n",
      "98.909\n",
      "93.7374\n",
      "88.8464\n",
      "84.2109\n",
      "79.8298\n",
      "75.6782\n",
      "71.7511\n",
      "68.0318\n",
      "64.5081\n",
      "61.1721\n",
      "58.01\n",
      "55.0165\n",
      "52.1836\n",
      "49.4977\n",
      "46.9526\n",
      "44.5445\n",
      "42.2595\n",
      "40.0946\n",
      "38.0441\n",
      "36.1034\n",
      "34.2603\n",
      "32.5135\n",
      "30.8576\n",
      "29.2883\n",
      "27.801\n",
      "26.3899\n",
      "25.0524\n",
      "23.7846\n",
      "22.5814\n",
      "21.4405\n",
      "20.3572\n",
      "19.331\n",
      "18.3581\n",
      "17.4339\n",
      "16.5586\n",
      "15.7278\n",
      "14.9386\n",
      "14.1906\n",
      "13.4804\n",
      "12.8063\n",
      "12.1661\n",
      "11.5586\n",
      "10.9826\n",
      "10.436\n",
      "9.91698\n",
      "9.42433\n",
      "8.95596\n",
      "8.51179\n",
      "8.08969\n",
      "7.68955\n",
      "7.30887\n",
      "6.94782\n",
      "6.60508\n",
      "6.27905\n",
      "5.96911\n",
      "5.67559\n",
      "5.39618\n",
      "5.13108\n",
      "4.87912\n",
      "4.63968\n",
      "4.4123\n",
      "4.19605\n",
      "3.99055\n",
      "3.79544\n",
      "3.61004\n",
      "3.43382\n",
      "3.26582\n",
      "3.10702\n",
      "2.95589\n",
      "2.81214\n",
      "2.67513\n",
      "2.54559\n",
      "2.42177\n",
      "2.30443\n",
      "2.19273\n",
      "2.08653\n",
      "1.98557\n",
      "1.88964\n",
      "1.7983\n",
      "1.71166\n",
      "1.62889\n",
      "1.55067\n",
      "1.47591\n",
      "1.40488\n",
      "1.33741\n",
      "1.27317\n",
      "1.21199\n",
      "1.1539\n",
      "1.09856\n",
      "1.04598\n",
      "0.995957\n",
      "0.948152\n",
      "0.902933\n",
      "0.859728\n",
      "0.81865\n",
      "0.779665\n",
      "0.742697\n",
      "0.70733\n",
      "0.673636\n",
      "0.641642\n",
      "0.611059\n",
      "0.582035\n",
      "0.554233\n",
      "0.527929\n",
      "0.502873\n",
      "0.479053\n",
      "0.456579\n",
      "0.434946\n",
      "0.414422\n",
      "0.394775\n",
      "0.37608\n",
      "0.35839\n",
      "0.341432\n",
      "0.325361\n",
      "0.310036\n",
      "0.295473\n",
      "0.28156\n",
      "0.268338\n",
      "0.255774\n",
      "0.243787\n",
      "0.232273\n",
      "0.221436\n",
      "0.211172\n",
      "0.201204\n",
      "0.191775\n",
      "0.182775\n",
      "0.174268\n",
      "0.166097\n",
      "0.158325\n",
      "0.150962\n",
      "0.143908\n",
      "0.137192\n",
      "0.130799\n",
      "0.124718\n",
      "0.118899\n",
      "0.113353\n",
      "0.108074\n",
      "0.103085\n",
      "0.0983025\n",
      "0.09376\n",
      "0.0893918\n",
      "0.0852551\n",
      "0.0813017\n",
      "0.0775457\n",
      "0.0739547\n",
      "0.0705324\n",
      "0.0672704\n",
      "0.0641476\n",
      "0.0611505\n",
      "0.0583497\n",
      "0.0556572\n",
      "0.0531028\n",
      "0.0506565\n",
      "0.0483374\n",
      "0.0461534\n",
      "0.0440116\n",
      "0.0420279\n",
      "0.0401023\n",
      "0.0382378\n",
      "0.0364754\n",
      "0.0348058\n",
      "0.0332096\n",
      "0.0316954\n",
      "0.03025\n",
      "0.0288832\n",
      "0.0275636\n",
      "0.0263074\n",
      "0.0251159\n",
      "0.0239794\n",
      "0.0228743\n",
      "0.0218331\n",
      "0.0208622\n",
      "0.0199029\n",
      "0.019006\n",
      "0.0181544\n",
      "0.0173351\n",
      "0.0165532\n",
      "0.0158005\n",
      "0.015089\n",
      "0.014418\n",
      "0.0137657\n",
      "0.0131463\n",
      "0.0125661\n",
      "0.0120015\n",
      "0.0114757\n",
      "0.0109584\n",
      "0.0104739\n",
      "0.0100109\n",
      "0.00957239\n",
      "0.00915347\n",
      "0.00875711\n",
      "0.00837043\n",
      "0.00800635\n",
      "0.00766018\n",
      "0.00732649\n",
      "0.00701135\n",
      "0.00670542\n",
      "0.00641172\n",
      "0.00613634\n",
      "0.00587371\n",
      "0.00562352\n",
      "0.00538522\n",
      "0.0051584\n",
      "0.0049447\n",
      "0.00473373\n",
      "0.00453034\n",
      "0.00434251\n",
      "0.00415408\n",
      "0.00398166\n",
      "0.00381907\n",
      "0.00366332\n",
      "0.00351697\n",
      "0.00337123\n",
      "0.00323413\n",
      "0.00310327\n",
      "0.00297935\n",
      "0.00286091\n",
      "0.00274835\n",
      "0.00263796\n",
      "0.00253275\n",
      "0.00243188\n",
      "0.00233616\n",
      "0.00224434\n",
      "0.00215641\n",
      "0.00207442\n",
      "0.00199459\n",
      "0.00191781\n",
      "0.00184139\n",
      "0.00177548\n",
      "0.00170848\n",
      "0.00164476\n",
      "0.00158336\n",
      "0.0015241\n",
      "0.00146781\n",
      "0.00141708\n",
      "0.00136564\n",
      "0.00131468\n",
      "0.00126907\n",
      "0.0012214\n",
      "0.00117834\n",
      "0.00113669\n",
      "0.00109668\n",
      "0.00105801\n",
      "0.00102435\n",
      "0.000988021\n",
      "0.000957972\n",
      "0.000925151\n",
      "0.000893644\n",
      "0.000865436\n",
      "0.000836131\n",
      "0.000808995\n",
      "0.000784284\n",
      "0.00075799\n",
      "0.000734271\n",
      "0.00071049\n",
      "0.000688562\n",
      "0.000667438\n",
      "0.000647934\n",
      "0.000627091\n",
      "0.000608084\n",
      "0.000589768\n",
      "0.000572964\n",
      "0.000555148\n",
      "0.000539713\n",
      "0.000524665\n",
      "0.000508628\n",
      "0.00049528\n",
      "0.000481728\n",
      "0.000469162\n",
      "0.000456756\n",
      "0.000443034\n",
      "0.000431173\n",
      "0.00042001\n",
      "0.000407584\n",
      "0.000396667\n",
      "0.000386399\n",
      "0.000376583\n",
      "0.000366299\n",
      "0.000357165\n",
      "0.000347694\n",
      "0.000339318\n",
      "0.000330702\n",
      "0.00032281\n",
      "0.000313824\n",
      "0.000305759\n",
      "0.000297981\n",
      "0.000290756\n",
      "0.000283696\n",
      "0.000276107\n",
      "0.000270289\n",
      "0.000263288\n",
      "0.000257677\n",
      "0.000251233\n",
      "0.00024544\n",
      "0.000240141\n",
      "0.000234412\n",
      "0.000229572\n",
      "0.000224001\n",
      "0.000218929\n",
      "0.000214327\n",
      "0.000209184\n",
      "0.000204387\n",
      "0.000200099\n",
      "0.000195769\n",
      "0.000192456\n",
      "0.000187934\n",
      "0.000183882\n",
      "0.00018047\n",
      "0.000176857\n",
      "0.000172938\n",
      "0.000170042\n",
      "0.00016599\n",
      "0.000162918\n",
      "0.00015892\n",
      "0.000156579\n",
      "0.00015292\n",
      "0.000150083\n",
      "0.000147149\n",
      "0.000144482\n",
      "0.000141471\n",
      "0.000138411\n",
      "0.000136246\n",
      "0.000133485\n",
      "0.000131574\n",
      "0.000128583\n",
      "0.000126521\n",
      "0.000124006\n",
      "0.000121495\n",
      "0.000119457\n",
      "0.000117489\n",
      "0.000115466\n",
      "0.000113507\n",
      "0.000111696\n",
      "0.000110091\n",
      "0.000108505\n",
      "0.000106552\n",
      "0.000104584\n",
      "0.000102832\n",
      "0.000100839\n",
      "9.89626e-05\n",
      "9.70518e-05\n",
      "9.58348e-05\n",
      "9.41167e-05\n",
      "9.27019e-05\n",
      "9.1141e-05\n",
      "8.95005e-05\n",
      "8.81773e-05\n",
      "8.65853e-05\n",
      "8.52048e-05\n",
      "8.39943e-05\n",
      "8.25422e-05\n",
      "8.11835e-05\n",
      "8.02117e-05\n",
      "7.90556e-05\n",
      "7.81235e-05\n",
      "7.69974e-05\n",
      "7.56896e-05\n",
      "7.50108e-05\n",
      "7.37518e-05\n",
      "7.24157e-05\n",
      "7.14992e-05\n",
      "7.00089e-05\n",
      "6.93454e-05\n"
     ]
    }
   ],
   "source": [
    "# Code in file autograd/tf_two_layer_net.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# First we set up the computational graph:\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create placeholders for the input and target data; these will be filled\n",
    "# with real data when we execute the graph.\n",
    "x = tf.placeholder(tf.float32, shape=(None, D_in))\n",
    "y = tf.placeholder(tf.float32, shape=(None, D_out))\n",
    "\n",
    "# Create Variables for the weights and initialize them with random data.\n",
    "# A TensorFlow Variable persists its value across executions of the graph.\n",
    "w1 = tf.Variable(tf.random_normal((D_in, H)))\n",
    "w2 = tf.Variable(tf.random_normal((H, D_out)))\n",
    "\n",
    "# Forward pass: Compute the predicted y using operations on TensorFlow Tensors.\n",
    "# Note that this code does not actually perform any numeric operations; it\n",
    "# merely sets up the computational graph that we will later execute.\n",
    "h = tf.matmul(x, w1)\n",
    "h_relu = tf.maximum(h, tf.zeros(1))\n",
    "y_pred = tf.matmul(h_relu, w2)\n",
    "\n",
    "# Compute loss using operations on TensorFlow Tensors\n",
    "loss = tf.reduce_sum((y - y_pred) ** 2.0)\n",
    "\n",
    "# Compute gradient of the loss with respect to w1 and w2.\n",
    "grad_w1, grad_w2 = tf.gradients(loss, [w1, w2])\n",
    "\n",
    "# Update the weights using gradient descent. To actually update the weights\n",
    "# we need to evaluate new_w1 and new_w2 when executing the graph. Note that\n",
    "# in TensorFlow the the act of updating the value of the weights is part of\n",
    "# the computational graph; in PyTorch this happens outside the computational\n",
    "# graph.\n",
    "learning_rate = 1e-6\n",
    "new_w1 = w1.assign(w1 - learning_rate * grad_w1)\n",
    "new_w2 = w2.assign(w2 - learning_rate * grad_w2)\n",
    "\n",
    "# Now we have built our computational graph, so we enter a TensorFlow session to\n",
    "# actually execute the graph.\n",
    "with tf.Session() as sess:\n",
    "    # Run the graph once to initialize the Variables w1 and w2.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "    # Create numpy arrays holding the actual data for the inputs x and targets y\n",
    "    x_value = np.random.randn(N, D_in)\n",
    "    y_value = np.random.randn(N, D_out)\n",
    "    for _ in range(500):\n",
    "        # Execute the graph many times. Each time it executes we want to bind\n",
    "        # x_value to x and y_value to y, specified with the feed_dict argument.\n",
    "        # Each time we execute the graph we want to compute the values for loss,\n",
    "        # new_w1, and new_w2; the values of these Tensors are returned as numpy\n",
    "        # arrays.\n",
    "        loss_value, _, _ = sess.run([loss, new_w1, new_w2],\n",
    "                                    feed_dict={x: x_value, y: y_value})\n",
    "        print(loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: nn\n",
    "The `nn` package defines a set of **Modules**, which are roughly equivalent to neural network layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 736.9913330078125\n",
      "1 680.4479370117188\n",
      "2 631.951171875\n",
      "3 589.7120971679688\n",
      "4 552.2689208984375\n",
      "5 518.9169921875\n",
      "6 488.7153625488281\n",
      "7 461.306640625\n",
      "8 436.1474609375\n",
      "9 412.55633544921875\n",
      "10 390.5765686035156\n",
      "11 369.9192810058594\n",
      "12 350.43499755859375\n",
      "13 331.92425537109375\n",
      "14 314.3824462890625\n",
      "15 297.6042785644531\n",
      "16 281.603271484375\n",
      "17 266.30328369140625\n",
      "18 251.73846435546875\n",
      "19 237.9233856201172\n",
      "20 224.7880401611328\n",
      "21 212.2001495361328\n",
      "22 200.21286010742188\n",
      "23 188.78427124023438\n",
      "24 177.89141845703125\n",
      "25 167.4981231689453\n",
      "26 157.6195068359375\n",
      "27 148.26565551757812\n",
      "28 139.3912811279297\n",
      "29 130.97816467285156\n",
      "30 123.00859832763672\n",
      "31 115.47413635253906\n",
      "32 108.3648452758789\n",
      "33 101.63951873779297\n",
      "34 95.3074722290039\n",
      "35 89.35140228271484\n",
      "36 83.7685546875\n",
      "37 78.52030181884766\n",
      "38 73.59060668945312\n",
      "39 68.96087646484375\n",
      "40 64.61405944824219\n",
      "41 60.543800354003906\n",
      "42 56.71101379394531\n",
      "43 53.124332427978516\n",
      "44 49.76331329345703\n",
      "45 46.62273406982422\n",
      "46 43.68167495727539\n",
      "47 40.93010711669922\n",
      "48 38.35974884033203\n",
      "49 35.95551300048828\n",
      "50 33.70814514160156\n",
      "51 31.60887908935547\n",
      "52 29.648454666137695\n",
      "53 27.815776824951172\n",
      "54 26.10181427001953\n",
      "55 24.50017547607422\n",
      "56 23.00116539001465\n",
      "57 21.599218368530273\n",
      "58 20.287681579589844\n",
      "59 19.062265396118164\n",
      "60 17.914541244506836\n",
      "61 16.8369197845459\n",
      "62 15.829442024230957\n",
      "63 14.885629653930664\n",
      "64 14.002177238464355\n",
      "65 13.175397872924805\n",
      "66 12.402547836303711\n",
      "67 11.678444862365723\n",
      "68 11.002455711364746\n",
      "69 10.36963176727295\n",
      "70 9.776859283447266\n",
      "71 9.220972061157227\n",
      "72 8.699583053588867\n",
      "73 8.211368560791016\n",
      "74 7.752950191497803\n",
      "75 7.322429180145264\n",
      "76 6.91791296005249\n",
      "77 6.538407325744629\n",
      "78 6.179110050201416\n",
      "79 5.841479778289795\n",
      "80 5.523960113525391\n",
      "81 5.224977970123291\n",
      "82 4.943600654602051\n",
      "83 4.678994178771973\n",
      "84 4.429381370544434\n",
      "85 4.194582939147949\n",
      "86 3.973208427429199\n",
      "87 3.7643582820892334\n",
      "88 3.5677247047424316\n",
      "89 3.3825032711029053\n",
      "90 3.207732915878296\n",
      "91 3.0425004959106445\n",
      "92 2.886854887008667\n",
      "93 2.7400312423706055\n",
      "94 2.60155987739563\n",
      "95 2.4709689617156982\n",
      "96 2.3476521968841553\n",
      "97 2.231093645095825\n",
      "98 2.120966911315918\n",
      "99 2.016937255859375\n",
      "100 1.91864013671875\n",
      "101 1.825675129890442\n",
      "102 1.7377101182937622\n",
      "103 1.654416799545288\n",
      "104 1.5756316184997559\n",
      "105 1.5011554956436157\n",
      "106 1.4306286573410034\n",
      "107 1.3638781309127808\n",
      "108 1.3006768226623535\n",
      "109 1.2407712936401367\n",
      "110 1.1839560270309448\n",
      "111 1.1300097703933716\n",
      "112 1.0787992477416992\n",
      "113 1.030245065689087\n",
      "114 0.9841524362564087\n",
      "115 0.9403687715530396\n",
      "116 0.8987710475921631\n",
      "117 0.8591960072517395\n",
      "118 0.8215867280960083\n",
      "119 0.7858505249023438\n",
      "120 0.7518612742424011\n",
      "121 0.719549834728241\n",
      "122 0.6887735724449158\n",
      "123 0.6594728827476501\n",
      "124 0.6316079497337341\n",
      "125 0.6050501465797424\n",
      "126 0.5797668695449829\n",
      "127 0.5556538701057434\n",
      "128 0.5326676964759827\n",
      "129 0.5107617378234863\n",
      "130 0.48986268043518066\n",
      "131 0.4699711501598358\n",
      "132 0.4510020315647125\n",
      "133 0.43292710185050964\n",
      "134 0.41564449667930603\n",
      "135 0.39916759729385376\n",
      "136 0.38342151045799255\n",
      "137 0.368384450674057\n",
      "138 0.3540304899215698\n",
      "139 0.34029388427734375\n",
      "140 0.3271482288837433\n",
      "141 0.31457436084747314\n",
      "142 0.3025449216365814\n",
      "143 0.29102468490600586\n",
      "144 0.27999716997146606\n",
      "145 0.2694368064403534\n",
      "146 0.2593275010585785\n",
      "147 0.24964354932308197\n",
      "148 0.24036292731761932\n",
      "149 0.23146380484104156\n",
      "150 0.2229418009519577\n",
      "151 0.21477605402469635\n",
      "152 0.20696236193180084\n",
      "153 0.19945555925369263\n",
      "154 0.19224940240383148\n",
      "155 0.18533629179000854\n",
      "156 0.17870379984378815\n",
      "157 0.17233411967754364\n",
      "158 0.166218101978302\n",
      "159 0.16034092009067535\n",
      "160 0.15469960868358612\n",
      "161 0.1492806375026703\n",
      "162 0.1440715789794922\n",
      "163 0.1390666961669922\n",
      "164 0.1342564821243286\n",
      "165 0.1296265423297882\n",
      "166 0.12517540156841278\n",
      "167 0.12089384347200394\n",
      "168 0.11677347868680954\n",
      "169 0.1128087118268013\n",
      "170 0.10899421572685242\n",
      "171 0.10532627254724503\n",
      "172 0.10179450362920761\n",
      "173 0.09839393198490143\n",
      "174 0.09511802345514297\n",
      "175 0.09196258336305618\n",
      "176 0.08892253786325455\n",
      "177 0.08599741756916046\n",
      "178 0.08317839354276657\n",
      "179 0.08045880496501923\n",
      "180 0.07783804088830948\n",
      "181 0.07531114667654037\n",
      "182 0.07287400215864182\n",
      "183 0.07052256911993027\n",
      "184 0.0682549774646759\n",
      "185 0.06606796383857727\n",
      "186 0.06395703554153442\n",
      "187 0.061920274049043655\n",
      "188 0.05995498597621918\n",
      "189 0.05805698037147522\n",
      "190 0.056227926164865494\n",
      "191 0.054462190717458725\n",
      "192 0.05275554582476616\n",
      "193 0.05110658332705498\n",
      "194 0.049513328820466995\n",
      "195 0.04797496646642685\n",
      "196 0.04648864269256592\n",
      "197 0.04505308344960213\n",
      "198 0.043664876371622086\n",
      "199 0.04232342913746834\n",
      "200 0.041026946157217026\n",
      "201 0.03977338597178459\n",
      "202 0.03856172412633896\n",
      "203 0.0373900830745697\n",
      "204 0.03625699505209923\n",
      "205 0.03516124188899994\n",
      "206 0.034101299941539764\n",
      "207 0.03307593613862991\n",
      "208 0.03208472207188606\n",
      "209 0.031125223264098167\n",
      "210 0.030197113752365112\n",
      "211 0.02929876185953617\n",
      "212 0.028429890051484108\n",
      "213 0.027588555589318275\n",
      "214 0.026774389669299126\n",
      "215 0.02598593756556511\n",
      "216 0.02522267773747444\n",
      "217 0.02448374032974243\n",
      "218 0.023768749088048935\n",
      "219 0.023077476769685745\n",
      "220 0.02240721695125103\n",
      "221 0.021757300943136215\n",
      "222 0.02112795040011406\n",
      "223 0.020517712458968163\n",
      "224 0.01992643065750599\n",
      "225 0.01935345120728016\n",
      "226 0.0187983475625515\n",
      "227 0.018260391429066658\n",
      "228 0.017738744616508484\n",
      "229 0.017232999205589294\n",
      "230 0.016742754727602005\n",
      "231 0.016267480328679085\n",
      "232 0.015806443989276886\n",
      "233 0.015359503217041492\n",
      "234 0.014926481060683727\n",
      "235 0.01450613234192133\n",
      "236 0.014098407700657845\n",
      "237 0.013702895492315292\n",
      "238 0.013319010846316814\n",
      "239 0.012946547009050846\n",
      "240 0.012585191056132317\n",
      "241 0.012234624475240707\n",
      "242 0.011894414201378822\n",
      "243 0.011564084328711033\n",
      "244 0.011243652552366257\n",
      "245 0.010932614095509052\n",
      "246 0.010630651377141476\n",
      "247 0.01033758744597435\n",
      "248 0.01005275547504425\n",
      "249 0.00977622251957655\n",
      "250 0.009507899172604084\n",
      "251 0.009247519075870514\n",
      "252 0.008994730189442635\n",
      "253 0.008749019354581833\n",
      "254 0.008510284125804901\n",
      "255 0.00827845185995102\n",
      "256 0.008053324185311794\n",
      "257 0.007834509946405888\n",
      "258 0.007622029632329941\n",
      "259 0.007415721192955971\n",
      "260 0.0072151231579482555\n",
      "261 0.007020309567451477\n",
      "262 0.006830956321209669\n",
      "263 0.006647027563303709\n",
      "264 0.00646826159209013\n",
      "265 0.006294607184827328\n",
      "266 0.006125840824097395\n",
      "267 0.005961827468127012\n",
      "268 0.005802387371659279\n",
      "269 0.005647401325404644\n",
      "270 0.005496733356267214\n",
      "271 0.005350332707166672\n",
      "272 0.005207955837249756\n",
      "273 0.005069540813565254\n",
      "274 0.004935005679726601\n",
      "275 0.004804202355444431\n",
      "276 0.004677013494074345\n",
      "277 0.004553346429020166\n",
      "278 0.004433170426636934\n",
      "279 0.004316229373216629\n",
      "280 0.004202499520033598\n",
      "281 0.004091869108378887\n",
      "282 0.0039843060076236725\n",
      "283 0.003879740834236145\n",
      "284 0.003778057871386409\n",
      "285 0.0036791034508496523\n",
      "286 0.003582798643037677\n",
      "287 0.0034891332034021616\n",
      "288 0.00339805381372571\n",
      "289 0.0033094242680817842\n",
      "290 0.0032233677338808775\n",
      "291 0.003139536827802658\n",
      "292 0.0030578786972910166\n",
      "293 0.0029786729719489813\n",
      "294 0.0029013575986027718\n",
      "295 0.0028261784464120865\n",
      "296 0.002752965549007058\n",
      "297 0.0026817487087100744\n",
      "298 0.0026124343276023865\n",
      "299 0.002544983522966504\n",
      "300 0.0024793215561658144\n",
      "301 0.002415439346805215\n",
      "302 0.0023532418999820948\n",
      "303 0.0022927194368094206\n",
      "304 0.0022337865084409714\n",
      "305 0.0021764382254332304\n",
      "306 0.002120609860867262\n",
      "307 0.0020662324968725443\n",
      "308 0.00201332475990057\n",
      "309 0.0019617960788309574\n",
      "310 0.001911649713292718\n",
      "311 0.0018628258258104324\n",
      "312 0.0018152683041989803\n",
      "313 0.0017689741216599941\n",
      "314 0.0017239240696653724\n",
      "315 0.001680030720308423\n",
      "316 0.0016373047837987542\n",
      "317 0.001595688983798027\n",
      "318 0.0015551422256976366\n",
      "319 0.001515665091574192\n",
      "320 0.001477218116633594\n",
      "321 0.0014397460035979748\n",
      "322 0.0014032938051968813\n",
      "323 0.0013677615206688643\n",
      "324 0.0013331794179975986\n",
      "325 0.001299491967074573\n",
      "326 0.0012666645925492048\n",
      "327 0.001234710798598826\n",
      "328 0.0012035754043608904\n",
      "329 0.0011732492130249739\n",
      "330 0.001143723726272583\n",
      "331 0.0011149655329063535\n",
      "332 0.0010869302786886692\n",
      "333 0.0010596219217404723\n",
      "334 0.00103302753996104\n",
      "335 0.0010070956777781248\n",
      "336 0.0009818484541028738\n",
      "337 0.0009572459966875613\n",
      "338 0.0009333181078545749\n",
      "339 0.0009099769522435963\n",
      "340 0.0008872334146872163\n",
      "341 0.0008650733507238328\n",
      "342 0.0008434575283899903\n",
      "343 0.0008224063785746694\n",
      "344 0.000801899645011872\n",
      "345 0.0007819174788892269\n",
      "346 0.0007624361314810812\n",
      "347 0.0007434554281644523\n",
      "348 0.0007249562186188996\n",
      "349 0.0007069365819916129\n",
      "350 0.0006893595564179122\n",
      "351 0.0006722420221194625\n",
      "352 0.000655556155834347\n",
      "353 0.0006393032381311059\n",
      "354 0.000623444328084588\n",
      "355 0.0006080023595131934\n",
      "356 0.0005929455510340631\n",
      "357 0.0005782644147984684\n",
      "358 0.0005639631417579949\n",
      "359 0.0005500264815054834\n",
      "360 0.0005364310345612466\n",
      "361 0.0005231917020864785\n",
      "362 0.0005102785653434694\n",
      "363 0.0004976846394129097\n",
      "364 0.0004854175786022097\n",
      "365 0.00047345709754154086\n",
      "366 0.00046179647324606776\n",
      "367 0.0004504362295847386\n",
      "368 0.00043935226858593524\n",
      "369 0.00042855311767198145\n",
      "370 0.0004180199757684022\n",
      "371 0.000407752173487097\n",
      "372 0.0003977394080720842\n",
      "373 0.00038798133027739823\n",
      "374 0.00037846490158699453\n",
      "375 0.00036917912075296044\n",
      "376 0.00036013845237903297\n",
      "377 0.00035131460754200816\n",
      "378 0.0003427151241339743\n",
      "379 0.000334329204633832\n",
      "380 0.00032615161035209894\n",
      "381 0.000318180478643626\n",
      "382 0.00031040390604175627\n",
      "383 0.0003028220380656421\n",
      "384 0.0002954314695671201\n",
      "385 0.0002882206463254988\n",
      "386 0.0002811928861774504\n",
      "387 0.00027433791547082365\n",
      "388 0.000267649011220783\n",
      "389 0.000261133536696434\n",
      "390 0.00025477330200374126\n",
      "391 0.00024857002426870167\n",
      "392 0.00024252661387436092\n",
      "393 0.00023662704916205257\n",
      "394 0.00023087722365744412\n",
      "395 0.00022526631073560566\n",
      "396 0.0002198027796112001\n",
      "397 0.0002144651662092656\n",
      "398 0.00020926023717038333\n",
      "399 0.00020418353960849345\n",
      "400 0.00019923770742025226\n",
      "401 0.00019441332551650703\n",
      "402 0.0001897029287647456\n",
      "403 0.00018511190137360245\n",
      "404 0.00018062430899590254\n",
      "405 0.0001762538158800453\n",
      "406 0.00017199106514453888\n",
      "407 0.00016783655155450106\n",
      "408 0.00016377793508581817\n",
      "409 0.00015981486649252474\n",
      "410 0.0001559593074489385\n",
      "411 0.00015219440683722496\n",
      "412 0.00014852135791443288\n",
      "413 0.00014493722119368613\n",
      "414 0.00014144011947792023\n",
      "415 0.00013803354522679\n",
      "416 0.00013470344129018486\n",
      "417 0.0001314592664130032\n",
      "418 0.0001282922603422776\n",
      "419 0.00012520531890913844\n",
      "420 0.00012219238851685077\n",
      "421 0.00011925149010494351\n",
      "422 0.00011638497380772606\n",
      "423 0.00011358377378201112\n",
      "424 0.00011085678852396086\n",
      "425 0.00010819196904776618\n",
      "426 0.00010559432848822325\n",
      "427 0.00010305995965609327\n",
      "428 0.00010058764019049704\n",
      "429 9.817363024922088e-05\n",
      "430 9.581693302607164e-05\n",
      "431 9.352232882520184e-05\n",
      "432 9.127787052420899e-05\n",
      "433 8.909194002626464e-05\n",
      "434 8.695781434653327e-05\n",
      "435 8.487659215461463e-05\n",
      "436 8.284638897748664e-05\n",
      "437 8.086479647317901e-05\n",
      "438 7.893069414421916e-05\n",
      "439 7.704204472247511e-05\n",
      "440 7.51993284211494e-05\n",
      "441 7.340217416640371e-05\n",
      "442 7.164968701545149e-05\n",
      "443 6.993998249527067e-05\n",
      "444 6.826971366535872e-05\n",
      "445 6.663814565399662e-05\n",
      "446 6.504736666101962e-05\n",
      "447 6.349685281747952e-05\n",
      "448 6.198296614456922e-05\n",
      "449 6.050522642908618e-05\n",
      "450 5.9062916989205405e-05\n",
      "451 5.7654251577332616e-05\n",
      "452 5.6279448472196236e-05\n",
      "453 5.494280776474625e-05\n",
      "454 5.3633408242603764e-05\n",
      "455 5.2357561798999086e-05\n",
      "456 5.1112503570038825e-05\n",
      "457 4.9895428674062714e-05\n",
      "458 4.87092329422012e-05\n",
      "459 4.7551715397275984e-05\n",
      "460 4.642453495762311e-05\n",
      "461 4.532087405095808e-05\n",
      "462 4.424459257279523e-05\n",
      "463 4.319328218116425e-05\n",
      "464 4.2168889194726944e-05\n",
      "465 4.116929994779639e-05\n",
      "466 4.0190450818045065e-05\n",
      "467 3.9237489545485005e-05\n",
      "468 3.830749119515531e-05\n",
      "469 3.739886960829608e-05\n",
      "470 3.6512665246846154e-05\n",
      "471 3.5646677133627236e-05\n",
      "472 3.480343730188906e-05\n",
      "473 3.39787220582366e-05\n",
      "474 3.3174499549204484e-05\n",
      "475 3.238966746721417e-05\n",
      "476 3.162272332701832e-05\n",
      "477 3.08744129142724e-05\n",
      "478 3.014471622009296e-05\n",
      "479 2.9430384529405273e-05\n",
      "480 2.873711309803184e-05\n",
      "481 2.8057391318725422e-05\n",
      "482 2.73945461231051e-05\n",
      "483 2.674752067832742e-05\n",
      "484 2.6116118533536792e-05\n",
      "485 2.549842611188069e-05\n",
      "486 2.4897286493796855e-05\n",
      "487 2.431099710520357e-05\n",
      "488 2.3735547074466012e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489 2.3175460228230804e-05\n",
      "490 2.262961061205715e-05\n",
      "491 2.2095293388701975e-05\n",
      "492 2.1576008293777704e-05\n",
      "493 2.1068051864858717e-05\n",
      "494 2.0570219930959865e-05\n",
      "495 2.0085230062250048e-05\n",
      "496 1.9613427866715938e-05\n",
      "497 1.9150698790326715e-05\n",
      "498 1.870006599347107e-05\n",
      "499 1.826129482651595e-05\n"
     ]
    }
   ],
   "source": [
    "# Code in file nn/two_layer_net_nn.py\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs, and wrap them in Variables.\n",
    "x = Variable(torch.randn(N, D_in))\n",
    "y = Variable(torch.randn(N, D_out), requires_grad=False)\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. Each Linear Module computes output from input using a\n",
    "# linear function, and holds internal Variables for its weight and bias.\n",
    "model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(D_in, H),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(H, D_out),\n",
    "        )\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
    "    # override the __call__ operator so you can call them like functions. When\n",
    "    # doing so you pass a Variable of input data to the Module and it produces\n",
    "    # a Variable of output data.\n",
    "    y_pred = model(x)\n",
    "  \n",
    "    # Compute and print loss. We pass Variables containing the predicted and true\n",
    "    # values of y, and the loss function returns a Variable containing the loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.data[0])\n",
    "    \n",
    "    # Zero the gradients before running the backward pass.\n",
    "    model.zero_grad()\n",
    "  \n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "    # parameters of the model. Internally, the parameters of each Module are stored\n",
    "    # in Variables with requires_grad=True, so this call will compute gradients for\n",
    "    # all learnable parameters in the model.\n",
    "    loss.backward()\n",
    "  \n",
    "    # Update the weights using gradient descent. Each parameter is a Variable, so\n",
    "    # we can access its data and gradients like we did before.\n",
    "    for param in model.parameters():\n",
    "        param.data -= learning_rate * param.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
