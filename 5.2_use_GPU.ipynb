{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "EPOCH = 2\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001\n",
    "DOWNLOAD_MNIST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),  # value : (0,1)\n",
    "    download=DOWNLOAD_MNIST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert test data into Variable, pick 2000 samples to speed up testing\n",
    "# add cuda()\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)\n",
    "test_x = Variable(torch.unsqueeze(test_data.test_data, dim=1), volatile=True).type(torch.FloatTensor)[:2000].cuda()/255.   # shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)\n",
    "test_y = test_data.test_labels[:2000].cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=5,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, x):                   # in forward, needs to consider batch_size dim.\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)                   # -> (batch_size, 32, 7, 7)\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN (\n",
      "  (conv1): Sequential (\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU ()\n",
      "    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (conv2): Sequential (\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU ()\n",
      "    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (out): Linear (1568 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "cnn.cuda()  # Moves all model parameters and buffers to the GPU.\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss()   # the target label is  not one-hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 2.3174 | test accuracy: 0.1980\n",
      "Epoch:  0 | train loss: 0.6783 | test accuracy: 0.8075\n",
      "Epoch:  0 | train loss: 0.2944 | test accuracy: 0.8855\n",
      "Epoch:  0 | train loss: 0.2428 | test accuracy: 0.9130\n",
      "Epoch:  0 | train loss: 0.1198 | test accuracy: 0.9340\n",
      "Epoch:  0 | train loss: 0.1148 | test accuracy: 0.9280\n",
      "Epoch:  0 | train loss: 0.0770 | test accuracy: 0.9425\n",
      "Epoch:  0 | train loss: 0.1487 | test accuracy: 0.9505\n",
      "Epoch:  0 | train loss: 0.0279 | test accuracy: 0.9635\n",
      "Epoch:  0 | train loss: 0.2090 | test accuracy: 0.9625\n",
      "Epoch:  0 | train loss: 0.0783 | test accuracy: 0.9690\n",
      "Epoch:  0 | train loss: 0.0220 | test accuracy: 0.9705\n",
      "Epoch:  0 | train loss: 0.0636 | test accuracy: 0.9710\n",
      "Epoch:  0 | train loss: 0.0858 | test accuracy: 0.9735\n",
      "Epoch:  0 | train loss: 0.0721 | test accuracy: 0.9710\n",
      "Epoch:  0 | train loss: 0.0312 | test accuracy: 0.9670\n",
      "Epoch:  0 | train loss: 0.0188 | test accuracy: 0.9780\n",
      "Epoch:  0 | train loss: 0.1066 | test accuracy: 0.9750\n",
      "Epoch:  0 | train loss: 0.1809 | test accuracy: 0.9735\n",
      "Epoch:  0 | train loss: 0.0852 | test accuracy: 0.9700\n",
      "Epoch:  0 | train loss: 0.0034 | test accuracy: 0.9740\n",
      "Epoch:  0 | train loss: 0.0106 | test accuracy: 0.9775\n",
      "Epoch:  0 | train loss: 0.0530 | test accuracy: 0.9780\n",
      "Epoch:  0 | train loss: 0.0359 | test accuracy: 0.9740\n",
      "Epoch:  1 | train loss: 0.1061 | test accuracy: 0.9685\n",
      "Epoch:  1 | train loss: 0.0610 | test accuracy: 0.9850\n",
      "Epoch:  1 | train loss: 0.0154 | test accuracy: 0.9820\n",
      "Epoch:  1 | train loss: 0.1299 | test accuracy: 0.9775\n",
      "Epoch:  1 | train loss: 0.0507 | test accuracy: 0.9750\n",
      "Epoch:  1 | train loss: 0.0894 | test accuracy: 0.9815\n",
      "Epoch:  1 | train loss: 0.1494 | test accuracy: 0.9750\n",
      "Epoch:  1 | train loss: 0.0607 | test accuracy: 0.9835\n",
      "Epoch:  1 | train loss: 0.0422 | test accuracy: 0.9805\n",
      "Epoch:  1 | train loss: 0.1627 | test accuracy: 0.9775\n",
      "Epoch:  1 | train loss: 0.0473 | test accuracy: 0.9770\n",
      "Epoch:  1 | train loss: 0.0842 | test accuracy: 0.9775\n",
      "Epoch:  1 | train loss: 0.0431 | test accuracy: 0.9825\n",
      "Epoch:  1 | train loss: 0.0020 | test accuracy: 0.9815\n",
      "Epoch:  1 | train loss: 0.0695 | test accuracy: 0.9795\n",
      "Epoch:  1 | train loss: 0.0754 | test accuracy: 0.9835\n",
      "Epoch:  1 | train loss: 0.0317 | test accuracy: 0.9785\n",
      "Epoch:  1 | train loss: 0.0608 | test accuracy: 0.9815\n",
      "Epoch:  1 | train loss: 0.0358 | test accuracy: 0.9825\n",
      "Epoch:  1 | train loss: 0.0791 | test accuracy: 0.9825\n",
      "Epoch:  1 | train loss: 0.0086 | test accuracy: 0.9830\n",
      "Epoch:  1 | train loss: 0.0051 | test accuracy: 0.9815\n",
      "Epoch:  1 | train loss: 0.0136 | test accuracy: 0.9800\n",
      "Epoch:  1 | train loss: 0.0295 | test accuracy: 0.9830\n"
     ]
    }
   ],
   "source": [
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x,y) in enumerate(train_loader):  # gives batch data, normalize x \n",
    "        b_x = Variable(x).cuda()   # batch x, add cuda()\n",
    "        b_y = Variable(y).cuda()   # batch y, add cuda()\n",
    "        \n",
    "        output = cnn(b_x)   # cnn output\n",
    "        loss = loss_func(output, b_y)  # cross_entropy loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            test_output = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].cuda().data.squeeze()\n",
    "            accuracy = sum(pred_y == test_y) / float(test_y.size(0))\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data[0], '| test accuracy: %.4f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
